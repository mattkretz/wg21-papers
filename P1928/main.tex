\newcommand\wgTitle{std::simd --- merge data-parallel types from the Parallelism TS 2}
\newcommand\wgName{Matthias Kretz <m.kretz@gsi.de>}
\newcommand\wgDocumentNumber{D1928R4}
\newcommand\wgGroup{LEWG}
\newcommand\wgTarget{\CC{}26}
%\newcommand\wgAcknowledgements{ }

\usepackage{mymacros}
\usepackage{wg21}
\setcounter{tocdepth}{2} % show sections and subsections in TOC
\hypersetup{bookmarksdepth=5}
\usepackage{changelog}
\usepackage{underscore}
\usepackage{comment}

\addbibresource{extra.bib}

\newcommand\simd[1][]{\type{simd#1}\xspace}
\newcommand\simdT{\type{simd<T>}\xspace}
\newcommand\valuetype{\type{value\_type}\xspace}
\newcommand\referencetype{\type{reference}\xspace}
\newcommand\whereexpression{\type{where\_expression}\xspace}
\newcommand\simdcast{\code{simd\_cast}\xspace}
\newcommand\mask[1][]{\type{simd\_mask#1}\xspace}
\newcommand\maskT{\type{simd\_mask<T>}\xspace}
\newcommand\fixedsizeN{\type{simd\_abi::fixed\_size<N>}\xspace}
\newcommand\fixedsizescoped{\type{simd\_abi::fixed\_size}\xspace}
\newcommand\fixedsize{\type{fixed\_size}\xspace}
\newcommand\wglink[1]{\href{https://wg21.link/#1}{#1}}
\DeclareRobustCommand\simdabi{\code{simd\_abi\MayBreak::\MayBreak}}

\renewcommand{\lst}[1]{Listing~\ref{#1}}
\renewcommand{\sect}[1]{Section~\ref{#1}}
\renewcommand{\ttref}[1]{Tony~Table~\ref{#1}}

\begin{document}
\selectlanguage{american}
\begin{wgTitlepage}
  After the Parallelism TS 2 was published in 2018, data-parallel types
  (\simdT) have been implemented and used.
  Now there is sufficient feedback to improve and merge Section 9 of the
  Parallelism TS 2 into the IS working draft.
\end{wgTitlepage}

\pagestyle{scrheadings}

\input{changelog}
\input{strawpolls}

\section{Introduction}
\cite{P0214R9} introduced \simdT and related types and functions into the Parallelism TS 2 Section 9.
The TS was published in 2018.
An incomplete and non-conforming (because P0214 evolved) implementation existed for the whole time P0214 progressed through the committee.
Shortly after the GCC 9 release, a complete implementation of Section 9 of the TS was made available.
Since GCC 11 a complete \code{simd} implementation of the TS is part of its standard library.

In the meantime the TS feedback progressed to a point where a merge should happen ASAP.
This paper proposes to merge only the feature-set that is present in the Parallelism TS 2.
(Note: The first revision of this paper did not propose a merge.)
If, due to feedback, any of these features require a change, then this paper (P1928) is the intended vehicle.
If a new feature is basically an addition to the wording proposed here, then it will progress in its own paper.

\subsection{Related papers}
\begin{description}
  \item[\wglink{P0350}] Before publication of the TS, SG1 approved \cite{P0350R0} which did not progress in time in LEWG to make it into the TS.
    \wglink{P0350} is moving forward independently.

  \item[\wglink{P0918}] After publication of the TS, SG1 approved \cite{P0918R2} which adds \code{shuffle}, \code{interleave}, \code{sum_to}, \code{multiply_sum_to}, and \code{saturated_simd_cast}.
    \wglink{P0918} will move forward independently.

  \item[\wglink{P1068}] R3 of the paper removed discussion/proposal of a \code{simd} based API because it was targeting \CC{}23 with the understanding of \code{simd} not being ready for \CC{}23.
    This is unfortunate as the presence of \code{simd} in the IS might lead to a considerably different assessment of the iterator/range-based API proposed in P1068.

  \item[\wglink{P0917}] The ability to write code that is generic wrt. arithmetic types and \code{simd} types is considered to be of high value (TS feedback).
    Conditional expressions via the \code{where} function were not all too well received.
    Conditional expressions via the conditional operator would provide a solution deemed perfect by those giving feedback (myself included).

  \item[draft on non-member {operator[]}] TODO

  \item[\wglink{P2600}] The fix for ADL is important to ensure the above two papers do not break existing code.

  \item[\wglink{P0543}] The paper proposing functions for saturation arithmetic expects \code{simd} overloads as soon as \code{simd} is merged to the IS.

  \item[\wglink{P0553}] The bit operations that are part of \CC{}20 expects \code{simd} overloads as soon as \code{simd} is merged to the IS.

  \item[\wglink{P2638}] Intel’s response to \wglink{P1915R0} for \code{std::simd}

  \item[\wglink{P2663}] \code{std::simd<std::complex<T>>}.

  \item[\wglink{P2664}] Permutations for \code{simd}.

  \item[\wglink{P2509}] \textcite{P2509R0} proposes a ``type trait to detect
    conversions between arithmetic-like types that always preserve the numeric
    value of the source object''. This matches the \textit{value-preserving}
    conversions the \code{simd} specification uses.
\end{description}
The papers \wglink{P0350}, \wglink{P0918}, \wglink{P2663}, \wglink{P2664}, and
the \code{simd}-based \wglink{P1068} fork currently have no shipping vehicle
and are basically blocked on this paper.

\section{Changes after TS feedback}\label{sec:changes}
\cite{P1915R0} (Expected Feedback from \code{simd} in the Parallelism TS 2) was published in 2019, asking for feedback to the TS.
I received feedback on the TS via the GitHub issue tracker, e-mails, and personal conversations.
There is also a lot of valuable feedback published in \wglink{P2638} ``Intel’s response to \wglink{P1915R0} for \code{std::simd}''.
This paper captures the major change requests but should still be considered a work-in-progress.

\subsection{improve ABI tags}
I received consistent feedback that \simdabi\code{compatible<T>} is the wrong default and it should rather be \simdabi\code{native<T>} instead.
All my tutorial material instructed users to use \stdx\code{native_simd<T>}.
There really is little use for \simdabi\code{compatible<T>}.
The preferred approach should be the use of \simdabi\code{native<T>} together with compiler flags that limit the available registers and instructions to whatever the user deems “compatible”.
Consequently, there is no reason to keep \simdabi\code{compatible<T>} in its current form.

Another common question was about a “fixed size” ABI tag, similar to \stdx\simdabi\code{fixed_size<N>} but without the ABI compatibility cost.%
\footnote{Implementations of the TS are encouraged to make passing \code{fixed_size} objects ABI compatible between different hardware generations and/or even different architectures.}
Basically, the ABI footgun should be as dangerous as \stdx\simdabi\code{native<T>}.
The answer to that FAQ is to use \stdx\simdabi\code{deduce_t<T, N>} as ABI tag.
This will provide you with a high-performance footgun, if supported, but might also fall back to \stdx\simdabi\code{fixed_size<N>}.
With \stdx\simdabi\code{deduce_t<T, N>} turning out to be used potentially more often than \stdx\simdabi\code{fixed_size<N>} the aliases and names should be revisited.
My proposal:

\begin{description}
  \item[\code{A0 = \simdabi native<T>}] \emph{(no change from the TS semantics)}\\
    \code{simd<T, A0>} abstracts a SIMD register (or similar) with highest performance on the target system (typically widest available register, but that's a QoI choice).
    Consequently, the number of elements is chosen by the implementation and may differ for different \code{T} and different compiler flags.
    \simdabi\code{native<T>} is an alias for an unspecified type.
    \simdabi\code{native<T>} can be an alias for \simdabi\code{scalar}.
    If \code{sizeof(simd<T, A0>)} or \code{alignof(\MayBreak{}simd\MayBreak{}<\MayBreak{}T, A0>)} in TU1 differ from the same expressions in TU2, then the types \code{A0} in TU1 and TU2 have a different name.

  \item[\code{A1 = \simdabi fixed_size<T, N>}] \emph{(different to the TS semantics)}\\
    \code{simd<T, A1>} abstracts one or more registers storing \code{N} values.
    The actual hardware resources might store more values; but instructions are generated to make it appear as if there are exactly \code{N} values stored and manipulated.

    Parameter passing may be ABI incompatible between different TUs when compiled with different compiler flags.
    Therefore, if \code{sizeof(simd<T, A0>)}%
    \footnote{\code{A0} is not a typo; this depends on \simdabi\code{native<T>}}
    or \code{alignof(\MayBreak{}simd\MayBreak{}<\MayBreak{}T, A0>)} in TU1
    differ from the same expressions in TU2, then the types \code{A1} in TU1
    and TU2 have a different name.
    This new requirement (wrt. the TS) is the reason for the additional
    \code{T} parameter.
    This allows an implementation to define the \code{fixed_size} alias as e.g.
    \lstinline@template <typename T, @
    \lstinline@int N> @
    \lstinline@using fixed_size @
    \lstinline@= _Fixed<N, native<T>>;@.
    \code{A1} and \code{A0} are always different types, i.e. even if \code{simd_size_v<T, A0> == N}.

    A major difference to \stdx\simdabi\code{fixed_size<N>} in the TS is about \code{simd_mask}.
    In order to support ABI stability the \code{simd_mask} implementation must choose one form of storage for all possible targets:
    \begin{itemize}
      \item full SIMD registers with all bits set to 1 or 0 per corresponding element
      \item bitmasks
      \item an array of \code{bool} or similar
    \end{itemize}
    The new intent for the \code{fixed_size<T, N>} ABI tag would be to allow \code{simd_mask<T, A1>} to use either choice depending only on compiler flags.

  \item[\code{A2 = \simdabi scalar}]\ \\
    No change.
\end{description}

At this point the \simdabi\code{deduce} facility seems to be obsolete.
However, it is still a useful tool for implementing the \code{rebind_simd} and \code{resize_simd} traits.
Without more compelling reason for removal, it should be merged as is.
%In theory, its ability to take an optional pack of ABI tags into account for its decision would be lost when removing \simdabi\code{deduce}.
%However, I have not heard of any users who want to use this feature.
%My recommendation is removal.%
%\footnote{For reference: my implementation simply ignores the pack of ABI tags given to \simdabi\code{deduce}.}

\subsubsection{Naming discussion}

For context on naming, consider the use-cases that the ABI tags serve:

\begin{description}
  \item[\simdabi\code{native<T>}] The equivalent to \code{T}: a direct abstraction of available hardware resources in terms of registers and instructions.

  \item[\simdabi\code{fixed_size<T, N>}] Higher abstraction level than \code{native<T>}: the user/algorithm dictates the number of elements to be processed in parallel.
    The objects might not be direct mappings to hardware resources, but they use the best that is available on the given target system.

  \item[\simdabi\code{scalar}] The actual type of \code{native<T>} if the target hardware has no support for parallel processing of elements of \code{T}.%
    \footnote{A typical example is \simdabi\code{native<long double>}.}
    In addition, \code{simd<T, simd_abi::scalar>} can be a useful debugging tool.
\end{description}

For reference, the name \code{fixed_size} is my preference over the following alternatives:
\begin{itemize}
  \item \code{simd_abi::fixed_native<N>} with \code{simd} alias \code{fixed_native_simd<T, N>}
  \item \code{simd_abi::fixed<N>} with \code{simd} alias \code{fixed_simd<T, N>}
  \item \code{simd_abi::sized<N>} with \code{simd} alias \code{sized_simd<T, N>}
\end{itemize}

\subsection{Simplify/generalize casts}\label{sec:casts}

The change to the ABI tags requires a reconsideration of cast functions and
implicit and explicit casts between data-parallel types of different ABI tags.
This is in addition to TS feedback on casts being too strict or cumbersome to use.

\subsubsection{More (explicit) converting constructors}

The TS allows implicit casts between \code{fixed_size<N>} types that only
differ in element type and where the values are preserved (“every possible
value of \code{U} can be represented with type \code{value_type}”).

However, from experience with the TS, it is better to also enable implicit
conversions between any \code{simd} specializations with equal element count,
even if such a conversion might be non-portable between targets with different
native SIMD widths.
The expectation is, that users set up their types according to a pattern
similar to \lst{lst:simdtypespattern}.
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:simdtypespattern,caption={
  Recommended setup of \code{simd} types
}]
using  floatv = std::simd<float>;
using doublev = std::rebind_simd_t<double, floatv>;
using  int32v = std::rebind_simd_t<std:: int32_t, floatv>;
using uint32v = std::rebind_simd_t<std::uint32_t, floatv>;
using  int16v = std::rebind_simd_t<std:: int16_t, floatv>;
using uint16v = std::rebind_simd_t<std::uint16_t, floatv>;
// ...
\end{lstlisting}
Thus, users will work with a set of types that have equal number of elements by
construction.
Some of the types may use the \code{fixed_size} ABI tag and some may use an
extended ABI tag.
This detail should not stop the user from being able to cast between a
compiler-flag dependent subset of these types.

Besides a constraint on the number of elements being equal, the converting
constructor should be conditionally \code{explicit}:
Implicit casts are only allowed if the element type conversion is
value-preserving (same wording as in the TS).

This resolves major inconveniences when working with mixed-precision
operations (cf. \ttref{tt:better with conv ctors}).
\begin{tonytable}[Parallelism TS 2]{Improved generic code after adding converting constructors}\label{tt:better with conv ctors}
  \begin{lstlisting}
namespace stdx = std::experimental;

template <class T> void f(T a, int b)
{
  using I = std::conditional_t<
              stdx::is_simd_v<T>,
              stdx::rebind_simd_t<int, T>, int>;
  I c;
  if constexpr (stdx::is_simd_v<T>) {
    c = stdx::static_simd_cast<I>(a) + b;
  } else {
    c = static_cast<int>(a) + b;
  }
  g(c);
}
  \end{lstlisting}
  &
  \begin{lstlisting}
// assuming simd in namespace std

template <class T> void f(T a, int b)
{
  using I = std::conditional_t<
              std::is_simd_v<T>,
              std::rebind_simd_t<int, T>, int>;
  I c = static_cast<I>(a) + b;





  g(c);
}
  \end{lstlisting}
\end{tonytable}%
Type conversions for \code{simd} are still less error-prone than builtin types,
because conversions that might lose information require an explicit cast.
Also, unintended widening of the SIMD register size can happen, but typically
leads to the need for an explicit cast in the complete statement (cf.
\lst{lst:mixedprecision}).

\begin{lstlisting}[numbers=left,float={hbtp},label=lst:mixedprecision,caption={
  Mixed precision code using the types from \lst{lst:simdtypespattern}, ensuring equal element count
}]
void f(int32v a, doublev b, floatv c)
{
  doublev x = a * b + c; // OK: implicit (value-preserving) conversion from int and float
    // to double. Requires twice the register space, but there's no way around it and the
    // result type requires it anyway.
  int32v y = a * b; // ERROR: implicit conversion from double to int not value-preserving
  int32v z1 = static_cast<int32v>(a * b); // OK: cast hints at implicit register widening
  int32v z2 = a * static_cast<int32v>(b); // OK
}
\end{lstlisting}

\subsubsection{Remove named cast functions}

From the cast functions \stdx\code{to_fixed_size}, \stdx\code{to_native}, and
\stdx\code{to_compatible} only the conversions from \simdabi\code{fixed_size<T,
N>} to \simdabi\code{native<T>} and back may still benefit from a named cast
function.
Most importantly, the conversion from \code{native} to its \code{fixed_size}
counterpart benefits from a cast expression that does not require spelling out
the destination type.
However, since converting constructors are provided by the standard library, it
is simple for users to define their own \code{to_fixed_size} function if they
want one (e.g.
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:userdefined-to-fixed-size,caption={
  Example of a user-defined \code{to_fixed_size} implementation if explicit casts are provided
}]
template <typename T>
constexpr std::fixed_size_simd<T, std::simd_size_v<T>> to_fixed_size(std::simd<T> x)
{
  return x;
}
\end{lstlisting}
\lst{lst:userdefined-to-fixed-size}).
The reverse cast can trivially be spelled out as \code{static_cast<simd<T>>(y)}
in program code.
The only motivation for adding a \code{to_native} function would be the
provision of a counterpart for the \code{to_fixed_size} cast function.

Besides the functions only implementing trivial implicit casts, there is little
to no need for these functions.
The named cast functions are therefore removed altogether.

\subsubsection{Remove \code{simd_cast} and \code{static_simd_cast}}
There are two cast function templates in the TS: \code{simd_cast} and
\code{static_simd_cast}.
The former is equivalent to the latter except that only value-preserving
conversions are allowed.
The template parameter can either be a \code{simd} specialization or a
vectorizable type \code{T}.
In the latter case, the cast function determines the return type as
\code{fixed_size_simd<T, input.size()>}.

Since we allow all conversions covered by \stdx\code{simd_cast} and
\stdx\code{static_simd_cast} via \std\code{simd} constructors, the cast
functions can be removed altogether.
The lost feature (cast via element type) can be replaced using
\code{rebind_simd} as shown in \ttref{tt:tsvsp1928casts}.
\begin{tonytable}[Parallelism TS 2]{Casting without specifying the target ABI tag}\label{tt:tsvsp1928casts}
  \begin{lstlisting}
template <typename V>
void f(V x)
{
  const auto y = stdx::static_simd_cast<double>(x);
  // ...
}
  \end{lstlisting}
  &
  \begin{lstlisting}
template <typename V>
void f(V x)
{
  const auto y = std::rebind_simd_t<double, V>(x);
  // ...
}
  \end{lstlisting}
\end{tonytable}%

\subsubsection{mask casts}
\code{simd_mask} casts should work when \code{simd} casts work.
I.e. if \code{simd<T0, A0>} is implicitly convertible to \code{simd<T1, A1>}
then \code{simd_mask<T0, A0>} is implicitly convertible to \code{simd_mask<T1,
A1>}.
The reverse (if \code{simd_mask} is convertible then \code{simd} is
convertible) does not have to be true.
Specifically, the TS allows all \code{fixed_size<N>} mask to be
interconvertible, irrespective of the element type.
For the IS merge, the proposal is to make this more consistent with \code{simd}
while also preserving most of the convenience:
Allow implicit conversions if the \code{sizeof} the element types are equal,
otherwise the conversion must be explicit.

Conversions with different element count are not possible via a constructor
(consistent with \code{simd}).
This would require a different function, such as the \code{resize<N>(simd)}
function proposed by \textcite{P2638R0}.

\subsubsection{Complete casts for \code{simd_mask}}
The \code{simd_cast} and \code{static_simd_cast} overloads for \code{simd_mask} were forgotten for the TS.
Without those casts (and no casts via constructors) mixing different arithmetic types is painful.
There is no motivation for forbidding casts on \code{simd_mask}.

The proposed changes for casts solve this issue.

\subsubsection{Summary of casts}

\begin{enumerate}
  \item \code{simd<T0, A0>} is convertible to \code{simd<T1, A1>} if
    \code{simd_size_v<T0, A0> == simd_size_v<T1, A1>}.

  \item \code{simd<T0, A0>} is implicitly convertible to \code{simd<T1, A1>}
    if, additionally, the conversion \code{T0} to \code{T1} is
    value-preserving.

  \item \code{simd_mask<T0, A0>} is convertible to \code{simd_mask<T1, A1>} if
    \code{simd_size_v<T0, A0> == simd_size_v<T1, A1>}.

  \item \code{simd_mask<T0, A0>} is implicitly convertible to
    \code{simd_mask<T1, A1>} if, additionally, \code{sizeof(T0) ==
    sizeof(T1)}.

  \item \code{simd<T0, A0>} can be \code{bit_cast}ed to \code{simd<T1, A1>} if
    \code{sizeof(simd<T0, A0>) == sizeof(simd<T1, A1>)}.

  \item \code{simd_mask<T0, A0>} can be \code{bit_cast}ed to \code{simd_mask<T1, A1>} if
    \code{sizeof(simd_mask<T0, A0>) == sizeof(simd_mask<T1, A1>)}.
\end{enumerate}

\subsection{Add \code{simd_mask} generator constructor}
The \code{simd} generator constructor is very useful for initializing objects
from scalars in a portable (i.e. different \code{simd::size()}) fashion.
The need for a similar constructor for \code{simd_mask} is less frequent, but,
even if only for consistency, there should be one.
Besides consistency, it is also useful, of course.
Consider a predicate function that is given without \code{simd} interface (e.g. from a library).
How do you construct a \code{simd_mask} from it?
With a generator constructor it is easy:
\medskip\begin{lstlisting}[style=Vc]
simd<T> f(simd<T> x, Predicate p) {
  const simd_mask<T> k([&](auto i) { return p(x[i]); });
  where(k, x) = 0;
  return x;
}
\end{lstlisting}
Without the generator constructor one has to write e.g.:
\medskip\begin{lstlisting}[style=Vc]
simd<T> f(simd<T> x, Predicate p) {
  simd_mask<T> k;
  for (size_t i = 0; i < simd<T>::size(); ++i) {
    k[i] = p(x[i]);
  }
  where(k, x) = 0;
  return x;
}
\end{lstlisting}
The latter solution makes it hard to initialize the \code{simd_mask} as \code{const}, is more verbose, is harder to optimize, and cannot use the sequencing properties the generator constructor allows.

Therefore add:
\begin{wgText}
\begin{itemdecl}
template<class G> simd_mask(G&& gen) noexcept;
\end{itemdecl}
\end{wgText}

\subsection{Default load/store flags to \code{element_aligned}}

Consider:
\medskip\begin{lstlisting}[style=Vc,numbers=left]
std::simd<float> v(addr, std::vector_aligned); @\label{lstline:vector_aligned}@
v.copy_from(addr + 1, std::element_aligned); @\label{lstline:load element_aligned}@
v.copy_to(dest, std::element_aligned); @\label{lstline:store element_aligned}@
\end{lstlisting}
Line~\ref{lstline:vector_aligned} supplies an optimization hint to the load operation.
Line~\ref{lstline:load element_aligned} says what really?
“Please don't crash.
I know this is not a vector aligned access\footnote{Of course, vector aligned is equivalent to element aligned if \code{simd<float>::size() == 1}}.”
Line~\ref{lstline:store element_aligned} says:
“I don't know whether it's vector aligned or not.
Compiler, if you know more, please optimize, otherwise just don't make it crash.”
(To clarify, the difference between lines~\ref{lstline:load element_aligned} and~\ref{lstline:store element_aligned} is what line~\ref{lstline:vector_aligned} says about the alignment of \code{addr}.)
In both cases of \code{element_aligned} access, the developer requested a behavior we take as given in all other situations.
Why does the TS force to spell it out in this case?

Since \CC{}20, we also have another option:
\medskip\begin{lstlisting}[numbers=left]
std::simd<float> v(std::assume_aligned<std::memory_alignment_v<std::simd<float>>>(addr)); @\label{lstline:assume_aligned}@
v.copy_from(addr + 1);
v.copy_to(dest);
\end{lstlisting}
This seems to compose well, except that line \ref{lstline:assume_aligned} is rather long for a common pattern in this interface.
Also, this removes implementation freedom because the library cannot statically determine the alignment properties of the pointer.

Consequently, as a minimal improvement to the TS keep the load/store flags as
is, but default them to \code{element_aligned}.
I.e.:
\medskip\begin{lstlisting}[numbers=left]
std::simd<float> v(addr, std::vector_aligned);
v.copy_from(addr + 1);
v.copy_to(dest);
\end{lstlisting}

\sect{sec:convertingLoadsAndStores} discusses an option for additional flags.

\subsection{Contiguous iterators for loads and stores}\label{sec:contiguousItLoadStore}

After Ranges and Concepts introduced \code{std::contiguous_iterator}, the
load/store interface for \code{simd} can easily be generalized from \code{U*}
to \code{std::contiguous_iterator} with additional constraints for
\code{input_iterator}/\code{output_iterator} and \code{iter_value_t}.
This was not a possible design choice for the TS but does make a lot of sense
to modernize with the merge.
Therefore, the merge generalizes the load/store interfaces to look like
\lst{lst:copyImpl}.
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:copyImpl,caption={
    \code{copy_from} and \code{copy_to} declarations using \code{contiguous_iterator}
}]
template <contiguous_iterator It, typename Flags = element_aligned_tag>
requires detail::vectorizable<iter_value_t<It>>
constexpr void copy_from(const It& first, Flags f = {});

template <contiguous_iterator It, typename Flags = element_aligned_tag>
requires output_iterator<It, Tp> && detail::vectorizable<iter_value_t<It>>
constexpr void copy_to(const It& first, Flags f = {}) const;
\end{lstlisting}

\subsection{\code{constexpr} everything}
The libstdc++ implementation implements the complete TS API as \code{constexpr} as an optional extension.
This is useful (e.g. for computing constants) and not a significant implementation burden.
Users (as well as \textcite{P2638R0}) have called for \code{constexpr}.
The merge consequently adds \code{constexpr} to all functions.

\subsection{Specify \code{simd::size} as \code{integral_constant}}
The TS specifies \code{simd::size} as a \code{static constexpr} function returning the number of elements of the \code{simd} specialization.
Instead of a function, this paper uses a static data member of type \code{std::integral_constant<std::size_t, N>}, which is both convertible to \code{std::size_t} and callable.
The upside of using a static data member is that it can be used as function parameter without conversion to integer and thus easily pass the size into a function as constant expression.
See \lst{lst:sizeparam} for an example.
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:sizeparam,caption={
    Example: Pass \code{simd::size} as ``constant expression function argument''
}]
template <std::ranges::contiguous_range R, std::size_t Size>
std::span<const std::ranges::range_value_t<R>, Size>
auto subscript(const R& r, std::size_t first, std::integral_constant<std::size_t, Size>) {
  return std::span<const std::ranges::range_value_t<R>, Size>(
    std::ranges::data(r) + first, Size());
}

void g(std::vector<float> data) {
  std::simd<float> v;
  for (std::size_t i = 0; i + v.size < data.size(); i += v.size) {
    v = subscript(data, i, v.size);  // simd::simd(span) to be proposed
    // ...
  }
}
\end{lstlisting}


\subsection{Replace \code{where} facilities}

The \code{where} functions and corresponding \code{where_expression} have been
the most controversial part going into the TS.
My interpretation of the feedback I received is that users can work with it but
do not find it intuitive.
Instead, many have asked for a blend / select / conditional operator instead.
Whenever I asked users whether they would like to use the \code{?:} operator I
got positive and often enthusiastic responses.
An overloaded \code{operator?:} would open the door to generic and intuitive
SIMD code.

A major motivation for the \code{where} function in the TS was its ability to
express masked \emph{operations} in addition to masked assignments.
This enables library implementations to explicitly use masked operation
intrinsics instead of resorting to an unmasked operation with subsequent masked
assignment.
The latter can be contracted to a masked operation by compilers, but obviously
there's no guarantee.
In any case, the topic is a QoI issue that doesn't have to dictate the API.

If \code{operator?:} had been overloadable when I designed \stdx\simd{} then I
would have propopsed \code{?:} overloads for \code{simd_mask} and \code{simd}.
Consequently, \code{where} would likely not have existed.
Sadly we still cannot overload \code{operator?:} even though there has been
positive feedback in EWG-I.
That work is currently blocked on \cite{P2600R0}.

\subsubsection{Proposed replacements for \code{where}}

This paper proposes the following replacements for \stdx\code{where}:

\begin{itemize}
  \item Overloads for \code{simd\MayBreak{}::\MayBreak{}copy_from},
    \code{simd\MayBreak{}::\MayBreak{}copy_to},
    \code{simd_mask\MayBreak{}::\MayBreak{}copy_from},
    \code{simd_mask\MayBreak{}::\MayBreak{}copy_to}, \code{reduce},
    \code{hmin}, and \code{hmax} with additional \code{simd_mask} parameter.

    There are still open questions on these functions, discussed in \sect{sec:maskedOverloads}.

  \item hidden friend \code{operator?:}\footnote{as soon as EWG lifts the
    restriction\ldots} / \code{conditional_operator} functions in \code{simd}
    and \code{simd_mask}:
    \begin{itemize}
      \item \lstinline@simd simd::operator?:(mask_type, simd, simd)@
      \item \lstinline@template <class U1, class U2>@\\
        \lstinline@requires convertible_to<simd_mask, rebind_simd_t<common_type_t<U1, U2>, simd_mask>@\\
        \lstinline@friend constexpr rebind_simd_t<common_type_t<U1, U2>, simd_type>@\\
        \lstinline@simd_mask::operator?:(simd_mask, U1, U2)@
      \item \lstinline@simd_mask simd_mask::operator?:(simd_mask, simd_mask, simd_mask)@
      \item \lstinline@simd_mask simd_mask::operator?:(simd_mask<K, KAbi>, simd_mask, simd_mask<U, UAbi>)@\\
        (for disambiguation of the above because \code{simd_mask}s can be interconvertible)
      \item \lstinline@simd_mask simd_mask::operator?:(simd_mask, bool, bool)@\\
        (for consistency; it's not very useful)
    \end{itemize}

  \item facilities for converting \code{simd_mask<T>} to \code{simd<T>} with
    values \code{0} or \code{1}:
    \begin{itemize}
      \item \code{simd_mask::operator simd_type} (not \code{explicit},
        preferably with 4.1 of \cite{P2600R0} adopted)
      \item unary \code{simd_mask::operator+}; equivalent to \code{+(operator simd_type())}
      \item unary \code{simd_mask::operator-}; equivalent to \code{-(operator simd_type())}
      \item unary \code{simd_mask::operator\~{}}; equivalent to \code{\~{}(operator simd_type())}
    \end{itemize}
\end{itemize}

(Wording for the above is still TBD.)

\subsubsection{Examples}

\lst{lst:simdconditionals} presents a few simple examples of working with a
\code{simd_mask} result in the absence of \code{where}.
Note that the compiler I used implements the ADL fix proposed in \cite{P2600R0}
and implements \code{opertaor?:} overloading as explored in \cite{D0917}.

\begin{lstlisting}[numbers=left,float={hbtp},label=lst:simdconditionals,caption={
    \code{simd} conditionals without \code{where} and with \cite{P2600R0} and \cite{D0917}, showing the corresponding assembly output (\code{gcc -O2 -std=c++23 -march=skylake-avx512}; personal GCC 12.1 branch with patches implementing \cite{P2600R0} and \cite{D0917})
}]
auto f0(std::simd<int> x) { return x > 0 ? 2 * x : x; }
/*	vpxor	xmm1, xmm1, xmm1
	vpcmpd	k1, zmm1, zmm0, 1
	vpslld	zmm0{k1}, zmm0, 1
	ret
*/
auto f1(std::simd<int> x) { return x > 0 ? 1 : 0; }
/*	vmovdqa32	zmm1, zmm0
	vpxor		xmm0, xmm0, xmm0
	vpcmpd		k1, zmm0, zmm1, 1
	mov		eax, 1
	vpbroadcastd	zmm0{k1}{z}, eax
	ret
*/
auto f2(std::simd<int> x) { return std::simd(x > 0); }
/*	vmovdqa32	zmm1, zmm0
	vpxor		xmm0, xmm0, xmm0
	vpcmpd		k1, zmm0, zmm1, 1
	mov		eax, 1
	vpbroadcastd	zmm0{k1}{z}, eax
	ret
*/
auto f3(std::simd<int> x) { return -(x > 0); }
/*	vmovdqa32	zmm1, zmm0
	vpxor		xmm0, xmm0, xmm0
	vpcmpd		k0, zmm0, zmm1, 1
	vpmovm2d	zmm0, k0
	ret
*/
auto f4(std::simd<int> x) { return x > 0 ? -1 : 0; }
/*	vmovdqa32	zmm1, zmm0
	vpxor		xmm0, xmm0, xmm0
	vpcmpd		k0, zmm0, zmm1, 1
	vpmovm2d	zmm0, k0
	ret
*/
auto f5(std::simd<int> x) { return x > 0 ? true : false; }
/*	vmovdqa32	zmm1, zmm0
	vpxor		xmm0, xmm0, xmm0
	vpcmpd		k0, zmm0, zmm1, 1
	kmovw		eax, k0
	ret
*/
\end{lstlisting}

\begin{itemize}
  \item The function \code{f0} scales all positive values in \code{x} by 2.
    The compiler contracts the blending of \code{2 * x} and \code{x} with the
    multiply operation (a left shift by 1) to a masked left shift instruction.

  \item The functions \code{f1} and \code{f2} both return a \code{simd<int>}
    where all positive entries of \code{x} are replaced by 1 and the remaining
    entries are 0.
    I.e. converting the comparison result to \code{simd} works analogue to
    promotion of \bool to \intt.

  \item The functions \code{f3} and \code{f4} both return a \code{simd<int>}
    where all positive entries of \code{x} are replaced by -1 and the remaining
    entries are 0.
    The ISA allows a more efficient translation and the compiler recognizes the
    pattern in both variants.

  \item Finally, to complete the set, \code{f5} shows how one could even blend
    \code{bool} arguments into a \code{simd_mask}.
    The compiler recognizes that the conditional operator is a no-op and simply
    returns the result of the comparison itself.
\end{itemize}

\begin{tonytable}[Parallelism TS 2]{Counting positive values in a \std\code{vector}}\label{tt:countingexample}
  \begin{lstlisting}
namespace stdx = std::experimental;
int count_positive(
  const std::vector<stdx::native_simd<float>>& x)
{
  // simplify generated assembly:
  if (x.size() == 0) std::unreachable();
  using floatv = stdx::native_simd<float>;
  using intv = stdx::rebind_simd_t<int, floatv>;
  intv counter = {};
  for (stdx::simd v : x) {
    auto k = stdx::static_simd_cast<
               intv::mask_type>(v > 0);
    ++where(k, counter);
  }
  return reduce(counter);
}
/*	mov	edx, 1
	mov	rcx, QWORD PTR [rdi+8]
	mov	rax, QWORD PTR [rdi]
	vpxor	xmm0, xmm0, xmm0
	vxorps	xmm2, xmm2, xmm2
	vpbroadcastd	zmm1, edx
.L12:
	vcmpps	k1, zmm2, ZMMWORD PTR [rax], 1
	add	rax, 64

	vpaddd	zmm0{k1}, zmm0, zmm1
	cmp	rcx, rax
	jne	.L12
	vmovdqa	ymm1, ymm0
	vextracti64x4	ymm0, zmm0, 0x1
	vpaddd	ymm0, ymm1, ymm0
	vmovdqa	xmm1, xmm0
	vextracti64x2	xmm0, ymm0, 0x1
	vpaddd	xmm1, xmm1, xmm0
	vpshufd	xmm0, xmm1, 27
	vpaddd	xmm0, xmm0, xmm1
	vpunpckhqdq	xmm1, xmm0, xmm0
	vpaddd	xmm0, xmm0, xmm1
	vmovd	eax, xmm0
	vzeroupper
	ret
*/
  \end{lstlisting}
  &
  \begin{lstlisting}

int count_positive(
  const std::vector<std::simd<float>>& x)
{
  // simplify generated assembly:
  if (x.size() == 0) std::unreachable();
  using floatv = std::simd<float>;
  using intv = std::rebind_simd_t<int, floatv>;
  intv counter = {};
  for (std::simd v : x) {
    counter += v > 0;


  }
  return reduce(counter);
}
/*	mov	edx, 1
	mov	rcx, QWORD PTR [rdi+8]
	mov	rax, QWORD PTR [rdi]
	vpxor	xmm0, xmm0, xmm0
	vxorps	xmm3, xmm3, xmm3
	vpbroadcastd	zmm2, edx
.L9:
	vcmpps	k1, zmm3, ZMMWORD PTR [rax], 1
	add	rax, 64
	vmovdqa32	zmm1{k1}{z}, zmm2
	vpaddd	zmm0, zmm0, zmm1
	cmp	rcx, rax
	jne	.L9
	vmovdqa	ymm1, ymm0
	vextracti64x4	ymm0, zmm0, 0x1
	vpaddd	ymm0, ymm1, ymm0
	vmovdqa	xmm1, xmm0
	vextracti64x2	xmm0, ymm0, 0x1
	vpaddd	xmm1, xmm1, xmm0
	vpshufd	xmm0, xmm1, 27
	vpaddd	xmm0, xmm0, xmm1
	vpunpckhqdq	xmm1, xmm0, xmm0
	vpaddd	xmm0, xmm0, xmm1
	vmovd	eax, xmm0
	vzeroupper
	ret
*/
  \end{lstlisting}
\end{tonytable}%

\ttref{tt:countingexample} presents an algorithm for counting all positive
\code{float} values in a \code{std::vector}.
For simplicity, the code uses \code{vector<simd<float>>} and assumes the \code{vector}
is not empty.
If a \code{simd_mask} implicitly converts to a \code{simd} (as proposed and
analogue to \code{bool}), the code is simplified significantly.
However, at this point, the TS implementation compiles to a masked add
instruction while the implementation for this paper does not.
The difference is that the former executes an unmasked addition followed up by
a masked assignment while the latter converts the mask into a \code{simd} of 1s
and 0s followed up by an unmasked addition.
The compiler needs to recognize this pattern in order to reach the same
performance (QoI).

\subsection{Make use of \code{int} and \code{size_t} consistent}

The TS uses \code{int} as NTTP for
\begin{itemize}
  \item \stdx\simdabi\code{fixed_size},
  \item \stdx\code{fixed_size_simd},
  \item \stdx\code{fixed_size_simd_mask}, and
  \item \stdx\code{resize_simd}.
\end{itemize}
The constant \stdx\simdabi\code{max_fixed_size} is of type \code{int}.
The TS uses \code{size_t} as NTTP for
\begin{itemize}
  \item \code{split}, and
  \item \code{split_by}.
\end{itemize}
This paper uses \code{integral_constant<size_t, }\VSize{}\code{>} for
\begin{itemize}
  \item \code{simd_size<T, Abi>},
  \item \code{simd<T, Abi>::size}, and
  \item \code{simd_mask<T, Abi>::size}.
\end{itemize}
Finally, \code{simd_size_v<T, Abi>} is of type \code{size_t}.

All of these integers denote a SIMD width.
They should be consistent.
Since the \code{size} member will never get concensus to use type \code{int},
the decision falls on \code{size_t} for all.

The merge proposal therefore uses \code{size_t} for
\stdx\simdabi\code{fixed_size}, \stdx\code{fixed_size_simd},
\stdx\code{fixed_size_simd_mask}, \stdx\code{resize_simd}, and
\stdx\simdabi\code{max_fixed_size}.

\subsection{Clean up math function overloads}
The wording that produces \code{simd} overloads misses a few cases and leaves room for ambiguity.
There is also no explicit mention of integral overloads that are supported in \code{<cmath>} (e.g. \code{std::cos(1)} calling \code{std::cos(double)}).
At the very least, \code{std::abs(simd<\textit{signed-integral}>)} should be specified.

Also, from implementation experience, ``undefined behavior'' for domain, pole,
or range error is unnecessary.
It could either be an unspecified result or even match the expected result of
the function according to Annex F in the C standard.
The latter could possibly be a recommendation, i.e. QoI.
The intent is to avoid \code{errno} altogether, while still supporting
floating-point exceptions (possibly depending on compiler flags).

This needs more work and is not reflected in the wording at this point.

%Wording idea:
%\begin{wgText}
%  \setcounter{Paras}{2}
%  \pnum
%  For each function with at least one parameter of type
%  \term{floating-point-type} other than \tcode{abs}, the implementation also
%  provides additional overloads sufficient to ensure that:
%  \begin{enumerate}
%    \item If at least one argument has a type that is a specialization of \tcode{simd}, then,
%      \begin{itemize}
%        \item if any two arguments are specializations of \tcode{simd} with
%          different width, then overload resolution does not result in a usable
%          candidate ([over.match.general]) from the overloads provided by the
%          implementation; otherwise
%        % now all simd arguments have equal width, or arguments are non-simd
%        \item every argument that is a specialization of \tcode{simd}
%      \end{itemize}
%      if every argument corresponding to a \term{floating-point-type} parameter
%      has arithmetic type or is a specialization of \tcode{simd}, then every
%      such
%      argument is effectively cast to the floating-point type with the greatest
%      floating-point conversion rank and greatest floating-point conversion
%      subrank among the types of all such arguments, where arguments of integer
%      type are considered to have the same floating-point conversion rank as
%      \tcode{double}.
%
%    \item Otherwise, if every argument corresponding to a
%      \term{floating-point-type} parameter has arithmetic type, then every such
%      argument is effectively cast to the floating-point type with the greatest
%      floating-point conversion rank and greatest floating-point conversion
%      subrank among the types of all such arguments, where arguments of integer
%      type are considered to have the same floating-point conversion rank as
%      \tcode{double}.
%      If no such floating-point type with the greatest rank and subrank exists,
%      then overload resolution does not result in a usable candidate
%      ([over.match.general]) from the overloads provided by the implementation.
%  \end{enumerate}
%\end{wgText}

\section{Open questions}

\subsection{Alternatives to \code{hmin} and \code{hmax}}
The functions \code{hmin(simd)} and \code{hmax(simd)} are basically
specializations of \code{reduce(simd)}.
I received feedback asking for better names.

With \CC{}17, there was nothing equivalent to \code{std::plus<>} for minimum
and maximum.
Since the merge of Ranges (\CC{}20), we have \stdranges\code{min} and
\stdranges\code{max}.
The \code{reduce(simd)} specification requires the \code{binary_op} to be
callable with two \code{simd} arguments, though (split initial argument in
half, call \code{binary_op}, split again, call \code{binary_op}, \ldots until
only a scalar is left).
This doesn't work with \stdranges\code{min} (and \code{max}) because it
requires an lvalue reference as return type.
If we added another \code{operator()} to \stdranges\code{min}, then their
use with \code{reduce(simd)} would be slightly inconsistent:
\medskip\begin{lstlisting}
simd<unsigned> v = ...;
auto a = reduce(v, std::bit_and<>); // must type <>
auto b = reduce(v, std::ranges::min); // must *not* type <>
\end{lstlisting}

However, if \code{simd} will be an \code{input_range} (see \sect{sec:ranges})
then the
\stdranges\code{min(\MayBreak{}ranges\MayBreak{}::\MayBreak{}input_range
auto\&\&, ...)} overload matches and \stdranges\code{min(simd)} works out of
the box.
We could then leave it up to QoI to recognize the opportunity for a SIMD
implementation of the reduction.

Alternatively (or in addition) we could rename the TS functions to
\code{reduce_min(simd)} and \code{reduce_max(simd)}.

\subsubsection{Suggested Polls}

\wgPoll{We want to do something about \code{hmin} and \code{hmax}; i.e. the TS
status quo is not acceptable for the IS.}
{&&&&}

\wgPoll{Rename to \code{reduce_min} and \code{reduce_max}.}
{&&&&}

\wgPoll{Extend \stdranges\code{min} and \code{max} to allow prvalue return types.}
{&&&&}

\wgPoll{Remove \code{hmin} and \code{hmax} expecting \code{simd} to become a range.}
{&&&&}

\subsection{Make \code{simd_mask} reductions consistent with \code{<bit>}}
The functions in \code{<bit>} were added in \CC{}20 \cite{P0553R4} and now
\code{simd_mask} needs to adjust for consistency.
Overloads for \code{simd<\textit{unsigned integer type}>} will also have to be
added.
But not with this \emph{merge} paper.
I promise to write a follow-up paper.

The three relevant functions in the TS are
\begin{itemize}
  \item \code{popcount(simd_mask)} and \code{popcount(}\textit{bool}\code{)}:\\
    The names match.
    However, currently \code{popcount(bool)} is ill-formed.
    This would be very unfortunate for generic code that calls \code{popcount}
    on the result of a comparison.
    For \code{simd_mask<T>} this operation provides value, for \code{T} it
    simply casts the \code{bool} to an \code{int}.
    The TS merge would therefore add \code{bool} to the list of valid types for
    \code{popcount}.

  \item \code{find_first_set(simd_mask)} and \code{find_first_set(}\textit{bool}\code{)}:\\
    This matches either \code{countl_zero} or \code{countr_zero}, except that
    the \code{simd_mask} version has a precondition.
    Same issue for \code{bool} as discussed for \code{popcount}.

  \item \code{find_last_set(simd_mask)} and \code{find_last_set(}\textit{bool}\code{)}:\\
    This matches either \code{countl_zero} or \code{countr_zero}, except that
    the \code{simd_mask} version has a precondition.
    Same issue for \code{bool} as discussed for \code{popcount}.
\end{itemize}

I believe we should remove the precondition on the \code{simd_mask} reductions
and allow masks where \code{none_of} returns \code{true}.
Then behavior is identical to \code{countl_zero} and \code{countr_zero}.
The reason for the precondition was efficiency on older ISAs.
At this point, especially with the precedent set by the \code{count[lr]}
functions, I don't believe the performance issue is worth the UB.

Renaming the \code{find_first/last_set} functions is not obvious though.
Consider that a \code{simd_mask k} can be indexed via subscript operator.
Then \code{k[0]} identifies the first element in \code{k}.
For all of us who think left-to-right, it would therefore be intuitive to have
\code{countl_zero} be the replacement for \code{find_first_set}.
But if you were to convert \code{k} into a \std\code{bitset} and convert the
\code{bitset} into an unsigned integer, then \code{countl_zero} would have the
opposite meaning (starting from the most significant bit).
Indexing a \code{simd_mask} and a \code{bitset} is consistent as is the
confusion about left and right with regard to the integer representation of a
\code{bitset}\footnote{cf. \url{https://godbolt.org/z/ov78q1751}}.

I believe it was wrong to call a bit position left or right.
That is always ambiguous.
Assuming that we will not change the existing names, the consistent name to use
for \stdx\code{find_first_set} is \std\code{countr_zero}.
To put the new name into perspective take a look at \lst{lst:searchwithsimd}.
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:searchwithsimd,caption={
    SIMD algorithm to find a \code{char} in a \code{string}
}]
int find(char needle, const std::string& hay) {
  using V = std::simd<char>;
  for (std::size_t i = 0; i + V::size <= hay.size(); i += V::size) {
    const V chunk(hay.data() + i);
    if (any_of(chunk == needle)) {
      return i + countr_zero(chunk == needle);
      // was: i + find_first_set(chunk == needle) in the TS
    }
  }
}
\end{lstlisting}
My mental model is iterating the \code{string} from left to right, but on every
SIMD chunk I need a twist and search right to left.
I believe \code{countr_zero} is an indefensible name for returning the lowest
index where the mask is \code{true}.
On the other hand, using \code{countl_zero} would be too inconsistent.

My recommendation is to overload \code{count[lr]_zero}/\code{one} for
\code{simd} but \emph{not} for \code{simd_mask}.
Unless \ldots

\subsubsection{The story of element-wise operations}\label{sec:maskreductionsrename}
\begin{quote}{}
  Everything you can do with \code{T} you can do with \code{simd<T>},
  only that the operations apply element-wise.
\end{quote}
Since \code{simd_mask<T>} is the return type of \code{simd<T>} comparisons, the
goal for \code{simd_mask} is:
\begin{quote}{}
  Everything you can do with \code{bool} you can do with \code{simd_mask<T>},
  only that the operations apply element-wise.
\end{quote}

By that reasoning, \code{popcount(simd_mask)} should be element-wise
\code{popcount(bool)}, and \code{countr_zero(simd_mask)} should be element-wise
\code{countr_zero(bool)}.
The \code{<bit>} functions would therefore not be mask reductions.
If \code{<bit>} were extended to include \code{bool} overloads, there should
also be \code{simd_mask} overloads, applying element-wise.

As a consquence, the mask reductions need a different name than the
\code{<bit>} functions.
See Table \ref{tab:maskreductions} for a suggestion.
\begin{table}[hbtp]
  \caption{Mask reductions}
  \label{tab:maskreductions}
  \smaller
  \begin{tabular}{p{.45\textwidth}|p{.45\textwidth}}
    TS names & alternative names \\
\hline
  \begin{lstlisting}
void f(stdx::native_simd_mask<int> k) {
  bool all  = all_of(k);
  bool any  = any_of(k);
  bool none = none_of(k);
  int count = popcount(k);
  int first = find_first_set(k);
  int last  = find_last_set(k);
}
  \end{lstlisting}
  &
  \begin{lstlisting}
void f(std::simd_mask<int> k) {
  bool all  = reduce_and(k);
  bool any  = reduce_or(k);
  bool none = reduce_nand(k);
  int count = reduce_count(k); // or reduce_add
  int first = reduce_min_index(k);
  int last  = reduce_max_index(k);
}
  \end{lstlisting}
\end{tabular}%
\end{table}%
Note that if \code{simd_mask} becomes a \stdranges\code{input_range}, then
\stdranges\code{all_of(simd_mask)} will be well-formed and agree with the
result of \stdx\code{all_of}.
(Same for \code{any_of} and \code{none_of}.)
The naming precedent suggests that \code{all_of}, \code{any_of}, and
\code{none_of} should not be renamed.

My recommendation is to merge \code{all_of}, \code{any_of}, and
\code{none_of} without change and rename \code{popcount},
\code{find_first_set}, and \code{find_last_set} according to Table
\ref{tab:preferredmaskreductionnames}.
\begin{table}[htbp]
  \caption{Recommended renaming of mask reductions}
  \label{tab:preferredmaskreductionnames}
\begin{tabular}{p{.45\textwidth}|p{.45\textwidth}}
  TS name & IS name \\
\hline
\code{all_of} & \code{all_of} \\
\code{any_of} & \code{any_of} \\
\code{none_of} & \code{none_of} \\
\code{popcount} & \code{reduce_count} \\
\code{find_first_set} & \code{reduce_min_index} \\
\code{find_last_set} & \code{reduce_max_index} \\
\end{tabular}%
\end{table}%

\subsubsection{Remove \code{some_of}}

While we're at the topic.
Let's drop \stdx\code{some_of}.
Nobody understands or wants the reduction, apparently.
It can be added back later if really needed (unlikely).

\subsubsection{Suggested Polls}

\wgPoll{Mask reductions should use the \code{<bit>} functions.}
{&&&&}

\wgPoll{Rename mask reductions as proposed in \wgDocumentNumber{} Table \ref{tab:preferredmaskreductionnames}.}
{&&&&}

\wgPoll{Remove UB of \code{find_first_set} / \code{find_last_set}.}
{&&&&}

\wgPoll{Do note merge / remove \code{some_of}.}
{&&&&}

\subsection{Argument order and naming of masked overloads}\label{sec:maskedOverloads}

In the TS, where-expressions made it possible to reuse existing function names
and argument orders for masked operations.
With the removal of where-expressions the mask must become a function argument.
See \tabref{tab:callsWithoutWhere} for a possible pattern to replace where-expressions.
\begin{beforeaftertable}[Parallelism TS 2 & possible replacement]{Possible replacement for where-expressions}
  \label{tab:callsWithoutWhere}
  \begin{lstlisting}
stdx::native_simd<float> v = ...;
where(v > 0, v).copy_from(ptr, stdx::element_aligned);
where(v < 0, v).copy_to(ptr, stdx::element_aligned);
float pos_sum = reduce(where(v > 0, v));
  \end{lstlisting}
  &
  \begin{lstlisting}
std::simd<float> v = ...;
v.copy_from_if(ptr, v > 0);
v.copy_to_if(ptr, v < 0);
float pos_sum = reduce_if(v, v > 0);
  \end{lstlisting}
\end{beforeaftertable}%

There are more options, of course.
E.g. possible replacements for \stdx\code{where_expression::copy_from}:
\begin{itemize}
  \item \lstinline@v.copy_from_if(v > 0, ptr)@\\
    Here the condition directly follows the word ``if'', which seems helpful.
    However:
  \item \lstinline@v.copy_from_if(ptr, v > 0)@\\
    This argument order follows precedent from algorithms, which always append
    the predicate to the list of arguments (e.g. \code{copy_if(first, last,
    d_first, pred)}).
    In addition, the argument order matches the order of words in the function
    name: ``from'' --- \code{ptr}, ``if'' --- \code{mask}.
  \item \lstinline@v.copy_from(v > 0, ptr)@
  \item \lstinline@v.copy_from(ptr, v > 0)@
  \item \lstinline@v.copy_from_where(v > 0, ptr)@
  \item \lstinline@v.copy_from_where(ptr, v > 0)@
\end{itemize}

The TS has no facility for masked load constructors.
I did not receive feedback that such a constructor is needed/wanted, so this paper will not propose one.

I propose to append \code{_if} to the masked functions and append the mask
argument (but before default arguments or additional arguments required for
masked operations, such as the \code{identity_element} in \code{reduce}).

\subsubsection{Suggested Polls}

\wgPoll{The names of masked ``overloads'' should include an \code{if} and follow the argument order proposed in \wgDocumentNumber{} \sect{sec:maskedOverloads}}
{&&&&}

%\subsection{Tuning masked loads and stores}
%
%The TS specifies masked loads and stores to prefer memory safety over performance:
%\begin{quote}{}
%  [§9.5 p9] Requires: [\ldots] the largest selected index is less than the number of values pointed to by mem.]
%
%  [§9.5 p19] Requires: [\ldots] for all selected indices i, i shall be less than the number of values pointed to by mem.
%\end{quote}
%I.e. the implementation is not allowed to read or write the memory locations that are masked off.
%Consequently,\\
%\lstinline@where(stdx::simd_mask<int>(false), v).copy_from(&*data.end(), stdx::element_aligned)@\\
%would not access any memory and the code would not invoke undefined behavior.
%However, this precludes efficient implementations on ISAs that have no native
%support for masked load and store operations.
%If a user ensures his memory allocations are always padded as necessary and
%thus expects highest performance, there is no good knob to turn to ``fast and
%faults are on you''.
%
%Such a knob could easily be provided via an additional load/store flag:\\
%\lstinline@v.copy_from_if(ptr, v > 0, std::vector_aligned | std::may_dereference_all)@.
\subsection{Converting loads \& stores consistency}\label{sec:convertingLoadsAndStores}

For the TS, we allowed pointers to any \emph{vectorizable} type as valid
arguments to \code{copy_from} and \code{copy_to}.
I.e. loads and stores can be converting operations without a clue in the code
other than the type of the pointer.
It can therefore happen that a conversion that is not value-preserving goes
unnoticed.
The broadcast and \code{simd} conversion constructurs guard against accidental
use of such conversions.

I have not received feedback that users wrote buggy because of this liberal
interface.
However, in the TS process this question was never really considered.
Therefore, I just wanted to show a suggestion for a stricter but just as
powerful interface.
\lst{lst:saferConvertingLoads} presents converting broadcast and cast
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:saferConvertingLoads,caption={
    Load-store flags as opt-in to converting loads and stores
}]
float  fmem[std::simd_size_v<float>] = {};
double dmem[std::simd_size_v<float>] = {};
short  smem[std::simd_size_v<float>] = {};

std::simd<float> a = 1.; // ERROR: double -> float conversion is not value-preserving
std::simd<float> b = std::rebind_simd_t<int, std::simd<float>>(1); // ERROR:
                                                  // int -> float is not value-preserving

// TS:
stdx::simd<float> ts;
ts.copy_from(fmem, stdx::element_aligned); // OK
ts.copy_from(dmem, stdx::element_aligned); // OK
ts.copy_from(smem, stdx::element_aligned); // OK

// idea, not status quo of this paper:
std::simd<float> v;
v.copy_from(fmem); // OK
v.copy_from(dmem); // ERROR: converting load
v.copy_from(smem); // ERROR: converting load

// Option (a) - one flag only:
v.copy_from(dmem, std::simd_converting); // OK
v.copy_from(smem, std::simd_converting); // OK

// Option (b) - two flags:
v.copy_from(dmem, std::simd_safe_cvt); // ERROR: double -> float is not value-preserving
v.copy_from(dmem, std::simd_any_cvt);  // OK
v.copy_from(smem, std::simd_safe_cvt); // OK
v.copy_from(smem, std::simd_any_cvt);  // OK
\end{lstlisting}
expressions, which are ill-formed because the type conversion is not
value-preserving.
The equivalent conversions on \code{copy_from} are well-formed, though.
I believe it would be better for users to opt-in to conversions on load and
store.
There are value-preserving and non-value-preserving conversions, which could be
combined into the same opt-in or we provide a separate spelling for
value-preserving conversions (the safe kind of conversion).

If LEWG is interested, I would be thankful for naming suggestions.
I do not believe that using ``safe'' is a good term here.

%
\subsection{Integration with ranges}\label{sec:ranges}
\code{simd} itself is not a container \cite{P0851R0}.
The value of a data-parallel object is not an array of elements but rather needs to be understood as a single opaque value that happens to have means for reading and writing element values.
I.e. \code{simd<int> x = \{\};} does not start the lifetime of \type{int} objects.
This implies that \code{simd} cannot model a contiguous range.
But \code{simd} can trivially model \code{random_access_range}.
However, in order to model \code{output_range}, the iterator of every non-const
\code{simd} would have to return an \code{element_reference} on dereference.
Without the ability of \code{element_reference} to decay to the element type
(similar to how arrays decay to pointers on deduction), I would prefer to
simply make \code{simd} model only \code{random_access_range}.

If \code{simd} is a range, then \code{std::vector<std::simd<float>> data} can
be flattened trivially via \code{data | std::views::join}.
This makes the use of ``arrays of \code{simd<T>}'' easier to integrate into
existing interfaces the expect ``array of \code{T}''.

I plan to pursue adding iterators and conversions to array and from
random-access ranges, specifically \code{span} with static extent, in a
follow-up paper.
I believe it is not necessary to resolve this question before merging
\code{simd} from the TS.

\subsection{Formatting support}\label{sec:formatting}
If \code{simd} \emph{is a} range, as suggested above and to be proposed in a
follow-up paper, then \code{simd} will automatically be formatted as a range.
This seems to be a good solution unless there is a demand to format \code{simd}
objects differently from \code{random_access_range}.

\subsection{Correct place for \code{simd} in the IS?}

While \code{simd} is certainly very important for numerics and therefore fits into the “Numerics library” clause, it is also more than that.
E.g. \code{simd} can be used for vectorization of text processing.
In principle \code{simd} should be understood similar to fundamental types.
Is the “General utilities library” clause a better place?
Or rename “Concurrency support library” to “Parallelism and concurrency support library” and put it there?
Alternatively, add a new library clause?

I am seeking feedback before making a recommendation.

\subsection{\code{element_reference} is overspecified}
\code{element_reference} is spelled out in a lot of detail.
It may be better to define its requirements in a list of requirements or a table instead.

This change is not reflected in the wording, pending encouragement from WG21 (mostly LWG).

\section{Wording: Add Section 9 of N4808 with modifications}\label{sec:wording}

The following section presents the wording to be applied against the \CC{}
working draft.

The wording still needs work:
\begin{itemize}
  \item Replace \code{where} \& \code{where_expression} wording with \code{conditional_operator} and masked overloads.
  \item Apply the new library specification style from P0788R3.
\end{itemize}

\begin{wgText}[In {[version.syn]}, add]
  \begin{codeblock}
    #define __cpp_lib_simd YYYYMML // also in <simd>
  \end{codeblock}
\end{wgText}
Adjust the placeholder value as needed so as to denote this proposal's date of adoption.

\begin{wgText}[Add a new subclause after §28.8 {[numerics.numbers]}]
  \setcounter{WGClause}{28}
  \setcounter{WGSubSection}{8}
  \lstset{%
    columns=fullflexible,
    deletedelim=**[is]{|-}{-|},
    moredelim=[is][\color{white}\fontsize{0.1pt}{0.1pt}\selectfont{}]{|-}{-|}
  }
  \input{wording}
\end{wgText}

\end{document}
% vim: sw=2 sts=2 ai et tw=0
