\newcommand\wgTitle{std::simd --- merge data-parallel types from the Parallelism TS 2}
\newcommand\wgName{Matthias Kretz <m.kretz@gsi.de>}
\newcommand\wgDocumentNumber{D1928R5}
\newcommand\wgGroup{LEWG}
\newcommand\wgTarget{\CC{}26}
\newcommand\wgAcknowledgements{Thanks to Daniel Towner, Jeff Garland, and Nicolas Morales for discussions and/or pull requests on this paper.}

\usepackage{mymacros}
\usepackage{wg21}
\setcounter{tocdepth}{2} % show sections and subsections in TOC
\hypersetup{bookmarksdepth=5}
\usepackage{changelog}
\usepackage{underscore}
\usepackage{multirow}

\addbibresource{extra.bib}

\newcommand\simd[1][]{\type{simd#1}\xspace}
\newcommand\simdT{\type{simd<T>}\xspace}
\newcommand\valuetype{\type{value\_type}\xspace}
\newcommand\referencetype{\type{reference}\xspace}
\newcommand\whereexpression{\type{where\_expression}\xspace}
\newcommand\simdcast{\code{simd\_cast}\xspace}
\newcommand\mask[1][]{\type{simd\_mask#1}\xspace}
\newcommand\maskT{\type{simd\_mask<T>}\xspace}
\newcommand\fixedsizeN{\type{simd\_abi::fixed\_size<N>}\xspace}
\newcommand\fixedsizescoped{\type{simd\_abi::fixed\_size}\xspace}
\newcommand\fixedsize{\type{fixed\_size}\xspace}
\newcommand\wglink[1]{\href{https://wg21.link/#1}{#1}}
\DeclareRobustCommand\simdabi{\code{simd\_abi\MayBreak::\MayBreak}}

\renewcommand{\lst}[1]{Listing~\ref{#1}}
\renewcommand{\sect}[1]{Section~\ref{#1}}
\renewcommand{\ttref}[1]{Tony~Table~\ref{#1}}
\renewcommand{\tabref}[1]{Table~\ref{#1}}

\begin{document}
\selectlanguage{american}
\begin{wgTitlepage}
  After the Parallelism TS 2 was published in 2018, data-parallel types
  (\simdT) have been implemented and used.
  Now there is sufficient feedback to improve and merge Section 9 of the
  Parallelism TS 2 into the IS working draft.
\end{wgTitlepage}

\pagestyle{scrheadings}

\input{changelog}
\input{strawpolls}

\section{Introduction}
\cite{P0214R9} introduced \simdT and related types and functions into the Parallelism TS 2 Section 9.
The TS was published in 2018.
An incomplete and non-conforming (because P0214 evolved) implementation existed for the whole time P0214 progressed through the committee.
Shortly after the GCC 9 release, a complete implementation of Section 9 of the TS was made available.
Since GCC 11 a complete \code{simd} implementation of the TS is part of its standard library.

In the meantime the TS feedback progressed to a point where a merge should happen ASAP.
This paper proposes to merge only the feature-set that is present in the Parallelism TS 2.
(Note: The first revision of this paper did not propose a merge.)
If, due to feedback, any of these features require a change, then this paper (P1928) is the intended vehicle.
If a new feature is basically an addition to the wording proposed here, then it will progress in its own paper.

\subsection{Related papers}
\begin{description}
  \item[\wglink{P0350}] Before publication of the TS, SG1 approved \cite{P0350R0} which did not progress in time in LEWG to make it into the TS.
    \wglink{P0350} is moving forward independently.

  \item[\wglink{P0918}] After publication of the TS, SG1 approved \cite{P0918R2} which adds \code{shuffle}, \code{interleave}, \code{sum_to}, \code{multiply_sum_to}, and \code{saturated_simd_cast}.
    \wglink{P0918} will move forward independently.

  \item[\wglink{P1068}] R3 of the paper removed discussion/proposal of a \code{simd} based API because it was targeting \CC{}23 with the understanding of \code{simd} not being ready for \CC{}23.
    This is unfortunate as the presence of \code{simd} in the IS might lead to a considerably different assessment of the iterator/range-based API proposed in P1068.

  \item[\wglink{P0917}] The ability to write code that is generic wrt. arithmetic types and \code{simd} types is considered to be of high value (TS feedback).
    Conditional expressions via the \code{where} function were not all too well received.
    Conditional expressions via the conditional operator would provide a solution deemed perfect by those giving feedback (myself included).

  \item[draft on non-member {operator[]}] TODO

  \item[\wglink{P2600}] The fix for ADL is important to ensure the above two papers do not break existing code.

  \item[\wglink{P0543}] The paper proposing functions for saturation arithmetic expects \code{simd} overloads as soon as \code{simd} is merged to the IS.

  \item[\wglink{P0553}] The bit operations that are part of \CC{}20 expects \code{simd} overloads as soon as \code{simd} is merged to the IS.

  \item[\wglink{P2638}] Intel’s response to \wglink{P1915R0} for \code{std::simd}

  \item[\wglink{P2663}] \code{std::simd<std::complex<T>>}.

  \item[\wglink{P2664}] Permutations for \code{simd}.

  \item[\wglink{P2509}] \textcite{P2509R0} proposes a ``type trait to detect
    conversions between arithmetic-like types that always preserve the numeric
    value of the source object''. This matches the \textit{value-preserving}
    conversions the \code{simd} specification uses.
\end{description}
The papers \wglink{P0350}, \wglink{P0918}, \wglink{P2663}, \wglink{P2664}, and
the \code{simd}-based \wglink{P1068} fork currently have no shipping vehicle
and are basically blocked on this paper.

\section{Changes after TS feedback}\label{sec:changes}
\cite{P1915R0} (Expected Feedback from \code{simd} in the Parallelism TS 2) was published in 2019, asking for feedback to the TS.
I received feedback on the TS via the GitHub issue tracker, e-mails, and personal conversations.
There is also a lot of valuable feedback published in \wglink{P2638} ``Intel’s response to \wglink{P1915R0} for \std\code{simd}''.

\subsection{improve ABI tags}
Summary:
\begin{itemize}
  \item Change the default SIMD ABI tag to \simdabi\code{native<T>} instead of \simdabi\code{compatible<T>}.
  \item Change \simdabi\code{fixed_size} to not recommend implementations make it ABI compatible.
\end{itemize}

For a discussion, see \wglink{P1928R3} Section 4.1.

Follow-up open questions are discussed in \sect{sec:simplifyfixedsize} and \sect{sec:basicsimdmask}.

\subsection{Simplify/generalize casts}\label{sec:casts}

For a discussion, see \wglink{P1928R3} Section 4.2.

Summary of changes wrt. TS:
\begin{enumerate}
  \item \code{simd<T0, A0>} is convertible to \code{simd<T1, A1>} if
    \code{simd_size_v<T0, A0> == simd_size_v<T1, A1>}.

  \item \code{simd<T0, A0>} is implicitly convertible to \code{simd<T1, A1>}
    if, additionally,
    \begin{itemize}
      \item the conversion \code{T0} to \code{T1} is value-preserving, and
      \item if both \code{T0} and \code{T1} are integral types, the integer
        conversion rank of \code{T1} is greater than or equal to the integer
        conversion rank of \code{T0}, and
      \item if both \code{T0} and \code{T1} are floating-point types, the
        floating-point conversion rank of \code{T1} is greater than or equal to
        the floating-point conversion rank of \code{T0}.
    \end{itemize}


  \item \code{simd_mask<T0, A0>} is convertible to \code{simd_mask<T1, A1>} if
    \code{simd_size_v<T0, A0> == simd_size_v<T1, A1>}.

  \item \code{simd_mask<T0, A0>} is implicitly convertible to
    \code{simd_mask<T1, A1>} if, additionally, \code{sizeof(T0) ==
    sizeof(T1)}.
    (This point is irrelevant if \sect{sec:basicsimdmask} is accepted.)

  \item \code{simd<T0, A0>} can be \code{bit_cast}ed to \code{simd<T1, A1>} if
    \code{sizeof(simd<T0, A0>) == sizeof(simd<T1, A1>)}.

  \item \code{simd_mask<T0, A0>} can be \code{bit_cast}ed to \code{simd_mask<T1, A1>} if
    \code{sizeof(simd_mask<T0, A0>) == sizeof(simd_mask<T1, A1>)}.
\end{enumerate}

\subsection{Add \code{simd_mask} generator constructor}

This constructor was added:
\begin{wgText}
\begin{itemdecl}
template<class G> simd_mask(G&& gen) noexcept;
\end{itemdecl}
\end{wgText}

For a discussion, see \wglink{P1928R3} Section 4.3.

\subsection{Default load/store flags to \code{element_aligned}}

Different to the TS, load/store flags default to \code{element_aligned}.
For a discussion, see \wglink{P1928R3} Section 4.4.

\subsection{Contiguous iterators for loads and stores}\label{sec:contiguousItLoadStore}

Different to the TS, loads and stores use \code{contiguous_iterator} instead of pointers.
For a discussion, see \wglink{P1928R3} Section 4.5.

\subsection{\code{constexpr} everything}
The merge adds \code{constexpr} to all functions.
For a discussion, see \wglink{P1928R3} Section 4.6.

\subsection{Specify \code{simd::size} as \code{integral_constant}}

Different to the TS, this paper uses a static data member \code{size} of type
\std\code{integral_constant<\MayBreak\std{}size_t, N>} in \simd and \mask.
For a discussion, see \wglink{P1928R3} Section 4.7.

\subsection{Replace \code{where} facilities}

The following load/store overloads have been added as a replacement for
\stdx\code{where_expression::copy_from} and \stdx\code{const_where_expression::copy_to}:
\begin{itemize}
  \item \code{simd::simd(contiguous_iterator, const mask_type\&, Flags = \{\})} (selected elements are copied from given range, otherwise use value-initialization)
  \item \code{simd::copy_from(contiguous_iterator, const mask_type\&, Flags = \{\})} (selected elements are copied from given range)
  \item \code{simd::copy_to(contiguous_iterator, const mask_type\&, Flags = \{\})} (selected elements are copied to given range)
  \item \code{simd_mask::simd_mask(contiguous_iterator, const mask_type\&, Flags = \{\})} (selected elements are copied from given range, otherwise use value-initialization)
  \item \code{simd_mask::copy_from(contiguous_iterator, const mask_type\&, Flags = \{\})} (selected elements are copied from given range)
  \item \code{simd_mask::copy_to(contiguous_iterator, const mask_type\&, Flags = \{\})} (selected elements are copied to given range)
\end{itemize}

The \code{reduce}, \code{hmin}, and \code{hmax} overloads with
\code{const_where_expression} argument have been replaced by overloads with
\simd and \mask arguments.

The following operators were added to \mask:
\begin{itemize}
  \item \code{simd_mask::operator simd<U, A>() const noexcept}
  \item \code{simd_mask::operator+() const noexcept}
  \item \code{simd_mask::operator-() const noexcept}
  \item \code{simd_mask::operator\~{}() const noexcept}
  \item \code{simd_mask::operator?:() const noexcept}
  \item \code{simd_mask operator?:(const simd_mask\&, const simd_mask\&, const simd_mask\&) noexcept}
  \item \code{simd_mask operator?:(const simd_mask\&, bool, bool) noexcept}
  \item \code{simd<nonpromoting_common_type_t<T0, T1> operator?:(const simd_mask\&, const T0\&, const T1\&) noexcept}
\end{itemize}

The following operator was added to \simd:
\begin{itemize}
  \item \code{operator?:(const mask_type\& mask, const simd\& a, const simd\& b) noexcept}
\end{itemize}

At this point, the use of \code{operator?:} obviously cannot work.
As long as we don't have the language feature for overloading \code{?:} the
following needs to happen (also reproduced at the beginning of the wording
section):
\begin{enumerate}
  \item Replace \code{operator?:} by \code{conditional_operator_impl}.
  \item Add a \std\code{conditional_operator(cond, a, b)} CPO that tries the following:
    \begin{itemize}
      \item If \code{conditional_operator_impl(cond, a, b)} can be found via ADL calls \code{conditional_operator_impl(cond, a, b)} unqualified, otherwise
      \item if \code{cond ? a : b} is well-formed, return its result, otherwise
      \item if \std\code{common_type_t<decltype(a), decltype(b)>} exists, cast \code{a} and \code{b} to this common type and apply \code{?:}.
    \end{itemize}
\end{enumerate}
Obviously, the use of a function (or CPO) instead of overloading
\code{operator?:} has a significant impact on generic code that would prefer to
keep the semantics of \code{?:}, which doesn't evaluate an expression unless
its result is actually needed.
For a function, we cannot pass expressions but only their results.
Relevant papers: \cite{P0927R2}, \cite{D0917}.

A list of alternative names for \std\code{conditional_operator}:
\begin{itemize}
  \item \std\code{ternary(cond, a, b)}
  \item \std\code{inline_if(cond, a, b)}
  \item \std\code{iif(cond, a, b)}
  \item \std\code{blend(cond, a, b)}
  \item \std\code{select(cond, a, b)}
  \item \std\code{choose(cond, a, b)}
\end{itemize}

For a discussion, see \wglink{P1928R3} Section 4.8 and 5.3.

\subsubsection{\code{simd_select} instead of \code{conditional_operator}}\label{sec:simd_select}
LEWG feedback on Tuesday in Varna:
\begin{itemize}
  \item Don't make it a CPO: user's shouldn't extend this.
  \item Make it “value based”, i.e. don't bother about references for non-simd arguments.
  \item Call it \code{simd_select}.
  \item Come back ASAP.
\end{itemize}

Proposal:
\begin{lstlisting}[escapechar=@]
namespace std
{
template <typename T, typename U>
  constexpr common_type_t<T, U>
  simd_select(bool c, T x, U y)
  { return c ? x : y; }

template <size_t N, typename Abi>
  constexpr auto
  simd_select(const basic_simd_mask<N, Abi>& k, const auto& x, const auto& y)
  -> decltype(@\UNSP{simd-select-impl}@(k, x, y))
  { return @\UNSP{simd-select-impl}@(k, x, y); }
}
\end{lstlisting}

Replace \code{operator?:} hidden friends with \UNSP{simd-select-impl} hidden
friends in \code{basic_simd} and \code{basic_simd_mask}.

\begin{description}
  \item[Pro] Continues to use the same conversion mechanisms as all the other
    (binary) operators (requires the use of hidden friends).

  \item[Con] Harder to discover/understand/document.
\end{description}

Wording TBD.

\subsection{Make use of \code{int} and \code{size_t} consistent}

Different to the TS, this paper uses \code{size_t} for
\stdx\simdabi\code{fixed_size}, \stdx\code{fixed_size_simd},
\stdx\code{fixed_size_simd_mask}, \stdx\code{resize_simd}, and
\stdx\simdabi\code{max_fixed_size}.
For a discussion, see \wglink{P1928R3} Section 4.9.

\subsection{Clean up math function overloads}
The wording that produces \code{simd} overloads misses a few cases and leaves room for ambiguity.
There is also no explicit mention of integral overloads that are supported in \code{<cmath>} (e.g. \std\code{cos(1)} calling \std\code{cos(double)}).
At the very least, \std\code{abs(simd<\textit{signed-integral}>)} should be specified.

Also, from implementation experience, ``undefined behavior'' for domain, pole,
or range error is unnecessary.
It could either be an unspecified result or even match the expected result of
the function according to Annex F in the C standard.
The latter could possibly be a recommendation, i.e. QoI.
The intent is to avoid \code{errno} altogether, while still supporting
floating-point exceptions (possibly depending on compiler flags).

This needs more work and is not reflected in the wording at this point.

%Wording idea:
%\begin{wgText}
%  \setcounter{Paras}{2}
%  \pnum
%  For each function with at least one parameter of type
%  \term{floating-point-type} other than \tcode{abs}, the implementation also
%  provides additional overloads sufficient to ensure that:
%  \begin{enumerate}
%    \item If at least one argument has a type that is a specialization of \tcode{simd}, then,
%      \begin{itemize}
%        \item if any two arguments are specializations of \tcode{simd} with
%          different width, then overload resolution does not result in a usable
%          candidate ([over.match.general]) from the overloads provided by the
%          implementation; otherwise
%        % now all simd arguments have equal width, or arguments are non-simd
%        \item every argument that is a specialization of \tcode{simd}
%      \end{itemize}
%      if every argument corresponding to a \term{floating-point-type} parameter
%      has arithmetic type or is a specialization of \tcode{simd}, then every
%      such
%      argument is effectively cast to the floating-point type with the greatest
%      floating-point conversion rank and greatest floating-point conversion
%      subrank among the types of all such arguments, where arguments of integer
%      type are considered to have the same floating-point conversion rank as
%      \tcode{double}.
%
%    \item Otherwise, if every argument corresponding to a
%      \term{floating-point-type} parameter has arithmetic type, then every such
%      argument is effectively cast to the floating-point type with the greatest
%      floating-point conversion rank and greatest floating-point conversion
%      subrank among the types of all such arguments, where arguments of integer
%      type are considered to have the same floating-point conversion rank as
%      \tcode{double}.
%      If no such floating-point type with the greatest rank and subrank exists,
%      then overload resolution does not result in a usable candidate
%      ([over.match.general]) from the overloads provided by the implementation.
%  \end{enumerate}
%\end{wgText}

\subsection{Add lvalue-qualifier to non-const subscript}\label{sec:lvalue-subscript}
The \code{operator[]} overloads of \code{simd} and \code{simd_mask} returned a
proxy reference object for non-\code{const} objects and the \code{value_type}
for \code{const} objects.
This made expressions such as \code{(x * 2)[0] = 1} well-formed.
However, assignment to temporaries can only be an error in the code (or code obfuscation).
Both \code{operator[]} overloads should be lvalue-ref qualified to make
\code{(x * 2)[0]} pick the const overload, which returns a prvalue that is not
assignable.

\subsection{Rename \code{simd_mask} reductions}
Summary:
\begin{itemize}
  \item The function \stdx\code{some_of} was removed.
  \item The function \stdx\code{popcount} was renamed to \std\code{reduce_count}.
  \item The function \stdx\code{find_first_set} was renamed to \std\code{reduce_min_index}.
  \item The function \stdx\code{find_last_set} was renamed to \std\code{reduce_max_index}.
\end{itemize}

For a discussion of this topic see \wglink{P1928R3} Section 5.2.

\subsection{Added constraints on operators and functions to match their underlying element types}

Previously some operators (e.g., \code{operator<}) and functions which relied on
some property of the element type (e.g., \tcode{min} relies on ordering)
were unconstrained. Operations which were not permitted on individual elements
were still available in the overload set for simd objects of those types.
Constraints have been added where necessary to remove such operators and
functions from the overload set where they aren't supported.


\subsection{Rename alignment flags and extend load/store flags for opt-in to conversions}\label{sec:renameandextendflags}

For some discussion, see \wglink{P1928R3} Section 5.4.

In addition to the TS, the load/store flag mechanism is extended to enable combination of flags.
The new flag enables conversions that are not \emph{value-preserving} on loads and stores.
Without the flag only \emph{value-preserving} conversions are allowed.

\subsubsection{Historical context}
The existing flags
\begin{itemize}
  \item \stdx\code{element_aligned},
  \item \stdx\code{vector_aligned}, and
  \item \stdx\code{overaligned<N>}
\end{itemize}
had no need for combining since they are exclusive.
Therefore, the TS included no such mechanism.
We should include a flag combining mechanism in any case, in order to allow
extensions without breaking implementations.
For reference, the original proposal \cite{N4184, §6.2} included a
\code{streaming} flag and a flag to assist in emitting prefetch instructions.
I implemented these flags in the Vc library more than 10 years ago.
For sake of proving the viability without too much complexity, SG1 asked to
reduce load store flags to what we finally shipped in the TS.

\subsubsection{Renaming alignment flags}
Now that the alignment flags move from \stdx{} to \std{}, we need to reconsider their names.
See \tabref{tab:alignmentnames} for a list of names that were considered.
\newcommand\simdflag[1]{
  \std\code{simd_#1},\newline
  \std\code{simd_flag_#1},\newline
  \std\code{simd_copy_#1},\newline
  \std\code{loadstore_#1},\newline
  \std\code{simd_flags\MayBreak{}::\MayBreak{}#1}
}
\newcommand\simdflagpref[1]{
  \std\code{loadstore_#1}
}
\begin{table}[hbtp]
  \caption{Name alternatives for alignment flags}
  \label{tab:alignmentnames}
  \smaller
\begin{tabular}{p{0.25\textwidth}p{0.35\textwidth}p{0.3\textwidth}}
  TS name & Ideas & Preference \\\hline

  \stdx\code{element_aligned}
  & \std\code{default_simd_flags},\newline
    \simdflag{element_aligned},\newline
    \simdflag{unaligned},\newline
    \simdflag{default}
  & \simdflagpref{default} \\\hline

  \stdx\code{vector_aligned}
  & \simdflag{aligned}
  & \simdflagpref{aligned} \\\hline

  \stdx\code{overaligned<N>}
  & \std\code{overaligned<N>},\newline
    \simdflag{overaligned<N>}
  & \simdflagpref{overaligned<N>} \\\hline

  ---
  & \simdflag{convert},\newline
    \simdflag{cvt_any},\newline
    \simdflag{any_cvt}
  & \simdflagpref{convert}
\end{tabular}
\end{table}
On my choices:
\begin{description}
  \item[\simdflagpref{default}] This is the default.
    There is no need to say anything about alignment.
    Alignment follows the assumptions of the rest of \CC{}; there's nothing
    special.
    It is useful to have a name for the default.
    Some generic programming patterns need to decide on default vs. aligned
    depending on template parameters.

  \item[\simdflagpref{aligned}] This flags says that the memory pointed to by
    the iterator follows stricter alignment requirements.
    Specifically it follows \code{memory_alignment_v<T, U>} (\code{T} is the
    \code{simd<T>} element type and \code{U} is the array element type).
    We should consider renaming \code{memory_alignment(_v)} to
    \code{simd_alignment(_v)} or \code{simd_loadstore_alignment(_v)}.

  \item[\simdflagpref{overaligned<N>}] This flags says that the memory pointed
    to by the iterator is aligned by \code{N} bytes.

  \item[\simdflagpref{convert}] This flag allows all conversions on load/store,
    in contrast to only \emph{value-preserving} conversions.
    It doesn't enable \emph{all} conversions, because value-preserving
    conversions are always enabled.
    But I cannot think of a more descriptive name that isn't at the same time
    also more confusing (``convert more'', ``convert anything'').
\end{description}

Note that the wording also allows additional implementation-defined load and
store flags.

The trait \code{is_simd_flag_type} has been removed because the flag parameter
is now constrained via the \code{loadstore_flag} class template.

As a result, executing a not-value-preserving store on 16-Byte aligned memory now reads as:
\begin{tabular}{p{.48\textwidth}|p{.48\textwidth}}
TS & \wgDocumentNumber \\\hline%
\smaller%
\begin{lstlisting}
float *addr = ...;
void f(stdx::native_simd<double> x) {
  x.copy_to(addr, stdx::overaligned<16>);
}

\end{lstlisting}
&\smaller%
\begin{lstlisting}
float *addr = ...;
void f(std::simd<double> x) {
  x.copy_to(addr, std::loadstore_convert |
                  std::loadstore_overaligned<16>);
}
\end{lstlisting}
\end{tabular}

\section{Open questions}

\subsection{Renaming \code{hmin} and \code{hmax} or else}\label{sec:hminhmax}
The functions \code{hmin(simd)} and \code{hmax(simd)} are basically
specializations of \code{reduce(simd)}.
I received feedback asking for better names.

We could rename the TS functions to:
\begin{enumerate}
  \item \code{reduce_min(simd)} and \code{reduce_max(simd)} (\emph{my
        recommendation --- unless convinced otherwise})
    \begin{description}
      \item[Pro] Clearly states that a reduction operation happens (optimized
        implementation will use tree reduction). Also consistent with the
        \code{reduce_} prefix for \mask reductions.
      \item[Con] Generic name, but \simd-specific (at this point).
    \end{description}

  \item \code{min_element(simd)} and \code{max_element(simd)}
    \begin{description}
      \item[Pro] Clearly states that it returns a single element, not a \simd.
      \item[Con] Mismatching behavior to \stdranges\code{min_element}, which
        returns an iterator.
    \end{description}

  \item \code{reduce_min_element(simd)} and \code{reduce_max_element(simd)}
    \begin{description}
      \item[Pro] Most explicit about performing a reduction and returning a
        single element.
      \item[Con] Rather verbose. Also the use of \code{min_element} in the name
        is again a mismatch with \stdranges\code{min_element}.
    \end{description}

  \item \code{horizontal_min(simd)} and \code{horizontal_max(simd)}
    \begin{description}
      \item[Pro] States that a horizontal operation is applied.
      \item[Con] We don't use the term „horizontal'' anywhere else.
    \end{description}

  \item \code{extract_min(simd)} and \code{extract_max(simd)}
    \begin{description}
      \item[Pro] The term “extract” states that a subset of elements (in this
        case a single element) will be extracted. This may or may not be a good
        matching name to the \code{extract} facility that we might add later.
      \item[Con] Inconsistent with \std\code{reduce(simd)} (maybe okay because
        slightly different: \std\code{reduce(\MayBreak{}simd)} returns an
        aggregate of all elements in the \simd, whereas \code{extract_max}
        “searches” for a certain element and returns its value - though also
        typically implemented as a tree reduction).
    \end{description}
\end{enumerate}

Alternatively, we can remove \code{hmin} and \code{hmax}, with the goal of
using different (more generic) facilities.
With \CC{}17, there was nothing equivalent to \std\code{plus<>} for minimum
and maximum.
Since the merge of Ranges (\CC{}20), we have \stdranges\code{min} and
\stdranges\code{max}.
The \code{reduce(simd)} specification requires the \code{binary_op} to be
callable with two \code{simd} arguments, though (split initial argument in
half, call \code{binary_op}, split again, call \code{binary_op}, \ldots until
only a scalar is left).
This doesn't work with \stdranges\code{min} (and \code{max}) because it
requires an lvalue reference as return type.
If we added another \code{operator()} to \stdranges\code{min}, then their
use with \code{reduce(simd)} would be slightly inconsistent:
\medskip\begin{lstlisting}
simd<unsigned> v = ...;
auto a = reduce(v, std::bit_and<>); // must type <>
auto b = reduce(v, std::ranges::min); // must *not* type <>
\end{lstlisting}

However, if \code{simd} will be an \code{input_range} (see \sect{sec:ranges})
then the
\stdranges\code{min(\MayBreak{}ranges\MayBreak{}::\MayBreak{}input_range
auto\&\&, ...)} overload matches and \stdranges\code{min(simd)} works out of
the box.
We could then leave it up to QoI to recognize the opportunity for a SIMD
implementation of the reduction.

\subsubsection{Suggested Polls}

\wgPoll{We want to do something about \code{hmin} and \code{hmax}; i.e. the TS
status quo is not acceptable for the IS.}
{&&&&}

\wgPoll{Rename to \code{reduce_min} and \code{reduce_max}.}
{&&&&}

\wgPoll{Extend \stdranges\code{min} and \code{max} to allow prvalue return
types (and remove \code{hmin}/\code{hmax}).}
{&&&&}

\wgPoll{Remove \code{hmin} and \code{hmax} expecting \code{simd} to become a
range.}
{&&&&}

\subsection{Simplify fixed_size}\label{sec:simplifyfixedsize}
To understand the following discussion it is worth remembering that given an
element type \code{T} and SIMD width \code{N}, the ABI tag is not necessarily
distinct.
For example, given AVX-512, \code{fixed_size_simd<float, 16>} could either be
one \code{zmm} register or two \code{ymm} registers.
Orthogonally, the \code{simd_mask} type could either be stored as a bit-mask or
as a vector-mask.
Thus, we already have four (somewhat) reasonable choices for the ABI tag.
If we consider different TUs compiled with different ``\code{-m}'' flags then
the possible set of ABI tags for ``\code{float}, \code{16}'' becomes even
larger.

There are only three possible reasons why \simdabi\code{fixed_size<T, N>} should
not be an alias for \simdabi\code{deduce_t<T, N>} (or rather a rename of
\code{deduce_t}):
\begin{enumerate}
  \item We want \code{N} in \code{fixed_size_simd<T, N>} to be deducible.

  \item We want to support overloading via differently named ABI tags (i.e. if
    the user types a different name, then the actual type should be different).

  \item We want the actual type name of \simdabi\code{fixed_size<T, N>} to be
    recognizable as ``fixed size'' and not just hide behind some
    implementation-defined ABI tag.
\end{enumerate}

In the TS, \code{fixed_size_simd<T, N>} is required to be deducible.
However, after the changes we did to \code{fixed_size} and conversions, there is
no good motivation for deducing \code{fixed_size_simd<T, N>} instead of
deducing \code{simd<T, Abi>}.
Let's just communicate that \code{simd<T, Abi>} is the one and only way to
deduce arbitrary length \code{simd} types.

In the TS, a user could write the following overload set:
\medskip\begin{lstlisting}
void f(stdx::native_simd<float>);

template <int N>
void f(stdx::fixed_size_simd<float, N>);
\end{lstlisting}
Besides \code{N} not being deducible anymore, if \code{N ==
stdx::native_simd<float>::size()}, then the overloads would clash, using the
same argument type.
However, again, after the changes we did to \code{fixed_size} and conversions,
there is probably no good reason left for declaring such an overload set.
Instead a user should write a single function template passing
\code{simd<float, Abi>}, deducing \code{Abi} and potentially constraining the
function using Concepts.

That leaves the question of diagnostics / debugging with regard to ABI tag names.
This argument can also go the other way:
By hiding the actual ABI tag used for implementing \code{fixed_size<T, N>} the
user has a harder time understanding what is going on.
So I don't think this argument has much weight.

\subsubsection{Suggested Poll}

Consequently, I propose the following poll:\\
\wgPoll{Remove \simdabi\code{fixed_size}, rename \simdabi\code{deduce_t} to
  \simdabi\code{fixed_size}, and remove (no public API) \simdabi\code{deduce}.
  Require \code{fixed_size_simd<T, simd_size_v<T>>} to be the same type as
  \code{simd<T>}. Require \code{fixed_size_simd<T, 1>} to be the same type as
  \code{simd<T, \simdabi{}scalar>}.}
{&&&&}

\subsection{Basic mask type?}\label{sec:basicsimdmask}
Now that \mask types have become interconvertible, the distinction between
\mask[<T, Abi>] and \mask[<U, Abi>] with \code{sizeof(T) == sizeof(U)} is gone.
Actually, the fact that the type is interconvertible makes it harder to use
(because it is easier to construct ambiguities).

Solution: \emph{Make \mask[<T, Abi>] an alias for \code{basic_simd_mask<sizeof(T), Abi>}.}

\begin{description}
  \item[Pros]
    \begin{itemize}
      \item reduces the number of template instantiations

      \item equivalent masks can now trivially be used on mixed type simd

      \item choosing the right template parameters for \mask is still simple
        and consistent with \simd
    \end{itemize}

  \item[Cons]
    \begin{itemize}
      \item It may be surprising that \mask[<T, Abi>] and \mask[<U, Abi>] are
        not different types.
        E.g. if someone wants to distinguish an overload set (why, though?).
        This is resolved by the alternative solution below.

      \item The \code{simd_mask::simd_type} member type must be removed or
        defined to an integer type of the corresponding \code{sizeof}.
        I.e. the mapping from mask type to simd type changes or doesn't exist
        anymore.

      \item Unary minus and unary plus on \mask objects must return an integer
        simd type.\\
        (\code{-(x < 0)} with \code{x} of type \code{simd<float>} would be of
        type \code{simd<int>} instead of \code{simd<float>})

      \item \code{sizeof(T) > sizeof(long long)} needs a different rule to
        determine the \code{simd_type} member and/or the unary operator return
        types.
        (E.g. \code{sizeof(long double) == 12} on Linux 32-bit,
        \code{sizeof(long double)} == 16 on Linux 64-bit)
        Proposed solution: Define \code{simd_mask<B, Abi>::simd_type} as
        \code{simd<I, Abi>} with \code{I} the largest standard signed integer
        type where \code{sizeof(I) <= B}.
    \end{itemize}
\end{description}

Alternative: \emph{Define the class template \code{template <size_t Bytes,
class Abi> class simd_mask;} and let users deal with the difference in template
parameters.}

Note that \code{simd<T, Abi>::mask_type} exists and is basically equivalent to
an alias template parameterized on \code{T} and \code{Abi}.

\subsubsection{Suggested Polls}

\wgPoll{Respecify \code{simd_mask<T, Abi>} as alias for \code{basic_simd_mask<sizeof(T), Abi>}.}
{&&&&}

\wgPoll{Specify \mask as \code{simd_mask<Bytes, Abi>}.}
{&&&&}

\wgPoll{Define \code{simd_mask<B, Abi>::simd_type} as \code{simd<I, Abi>} with \code{I} the largest standard signed integer type where \code{sizeof(I) <= B}.}
{&&&&}

\wgPoll{Do not define a \code{simd_type} member type, but use the above rule for the return type of unary minus and unary plus.}
{&&&&}

\subsection{Reconsider conversion rules}\label{sec:reconsider_conversions}

LEWG discussed conversion in Issaquah 2023.
There was some consensus in favor of: ``SIMD types and operations should be
value preserving, even if that means they're inconsistent with the builtin
numeric types.''
Comments on this poll were:
\begin{itemize}
  \item WF: I generally like the direction, in the sense of safety, but I'm
    not sure of the consequences of such a design.

  \item N: I would rather be consistently wrong than inconsistent.

  \item WA: I don't want to be inconsistent with how things have been for the last 30 years.

  \item WF: I'm not sure if we've evaluated the performance impact of this.

  \item N: Just because we've made a mistake in the past doesn't mean we have to keep making it. I'm not convinced that the new approach is the right thing.
\end{itemize}

LEWG then noticed a specifically tricky case when mixing \code{int} and \code{float}.
Which of these do we want?
\begin{itemize}
  \item \code{int * simd<float> = simd<float>}
  \item \code{int * simd<float> = simd<double>}
\end{itemize}

There was no consensus on how to resolve this correctly.
Note that \code{int} (and to some extent \code{unsigned int}) have a special
exception in the \emph{value-preserving} conversion rules.
Otherwise, a lot of code would be much more cumbersome to write (especially for
types that have no matching literals, e.g. \code{short}).

With the discussion on safety and correctness in \CC{} getting more traction,
there is a plausible chance that we will see a set of types that exhibit
``safer'' conversion behavior in the future.
A possible approach could be via \cite{P2509R0}, defining a trait for
value-preserving conversions.
This trait could then be used to define a numeric type, wrapping the existing
arithmetic types with conversions being conditionally \code{explicit} depending
on that trait.

When that happens, we will likely want to make these types \emph{vectorizable}
and then inherit the conversion rules of those types.

So why not let \code{simd<T>} inherit conversion behavior via
\std\code{constructible_from} and \std\code{convertible_to}?
Then such future numeric types conversion behavior will just fall in place.

The problem is that builtin arithmetic types behave differently to class types.
\begin{itemize}
  \item They are all interconvertible.
  \item When a binary operator is called with mixed types, there are rules
    ([expr.arith.conv]) to determine a common type that go beyond anything a
    class type can do.
  \item Integral promotions.
  \item And to top it off, there are no literals for \code{(un)signed char} and
    \code{(un)signed short} (i.e. you cannot initialize without an implicit or
    explicit conversion --- except value-init).
\end{itemize}

We could make all \code{simd} types interconvertible and implement binary
operators similar to \code{simd<another_common_type_t<T, U>>(simd<T>,
simd<U>)}\footnote{which is basically what my first paper on SIMD vector types
proposed \cite{N4184}}.
Though, we surely want to ignore integral promotions (otherwise
\code{simd<char>() + simd<char>()} has surprisingly bad performance
characteristics).
This would be going back to the original Vc library that was the basis of the
\code{simd} proposal (back in 2014).
Meaning, it has been done and it can be done.
But those binary operators are not really a pretty solution either.
And error messages when something goes wrong even less.

The type trait \code{another_common_type<T, U>} could implement
\code{common_type} without integer promotion (and assorted other tweaks to
reduce surprises\footnote{Who knew that
\code{common_type_t<std::integral_constant<int, -1>, unsigned short>} is
\code{unsigned short}?}).

The comment ``I would rather be consistently wrong than inconsistent.'' above
was missing this information.
There is no reasonable possibility to be ``consistently wrong'' here.
We have no other choice than being inconsistent.
Our only choice is what that inconsistency looks like.

In Issaquah, the idea of a ``value-preserving common type'' was voiced.
This would presumably mean that \code{int + float} can turn into \code{double}.
The trouble with such a trait is how to determine the correct answer if none of
the argument types is a value-preserving common type.
The situation is manageable as long as \code{simd} only supports arithmetic types.
But there exists a plausible future where fixed-point numbers, rational numbers,
\code{_BitInt}-like numbers, \ldots become \code{vectorizable}.
While I believe a solution could be developed, I am not convinced that it would
serve users well.
The tricky cases are probably best flagged as compile-time errors and resolved
via explicit cast.

Choices:
\begin{enumerate}
  \item Try to be as “consistently wrong” (i.e. consistent with builtin types)
    as possible, at the cost of interconvertible types (leads to ambiguity
    errors), more complex binary operators, and many subtle ways to
    unintentionally change types and potentially also pay in performance.

  \item\label{enum:binaryoptemplates} Variant of the above: Don't make \simd
    interconvertible, by defining the \simd conversion constructor as in the
    wording below.
    However, the broadcast constructor is a simple \code{simd(value_type x)},
    without any further constraints.
    Binary operators derive the return type (and common type for evaluating the
    operations) from a non-promoting common type of the operands.

  \item\label{enum:valuepreserving} Stick to the \emph{value-preserving} rules
    with (or without) exceptions for \code{int} and \code{unsigned int} as
    introduced in the TS.

  \item\label{enum:commontype} Consider a new rule-set that derives conversion
    rules (i.e. constraints on broadcast and conversion constructor) from a
    non-promoting common type of the participating types.
    Binary operators are still a simple hidden friend \code{simd
    operator+(simd, simd)}, requiring that the operands determine one of the
    operand types as their common type.
\end{enumerate}

Choice \ref{enum:commontype} would basically make conversions conditionally
explicit via \code{explicit(not std::same_as<another_common_type_t<T, U>, T>)}.

In such an implementation \code{int * simd<float>} is still of type
\code{simd<float>} (as is \code{simd<int> * simd<float>} and \code{simd<long
long> * simd<float>}).

With choice \ref{enum:valuepreserving} the \code{simd<int> * simd<float>} and
\code{simd<long long> * simd<float>} cases are ill-formed.

However, choice \ref{enum:commontype} makes initialization of
\code{simd<short>} (and similar) cumbersome, since no literal other than a
\code{char} literal is convertible to the \simd.
This is true for the plain value-preserving approach as well, which is why it
has exceptions for \code{int} and \code{unsigned int} on broadcast constructor
arguments.
This same exception could be used for choice \ref{enum:valuepreserving}, of
course.

Or, instead, we could allow arbitrary types if the library can determine at
compile-time that the \emph{value} of the argument can be converted without
narrowing.
This would be possible with \code{integral_constant} arguments, or rather
anything with a \code{static constexpr value} data member.
Then, \std\code{simd<short> x = std::cc<1>;} is well-formed while
\std\code{simd<short> x = 1;} is not.%
\footnote{Then we only need a language feature to turn constant expressions
into \code{integral_constant}/\code{constexpr_t}/etc. via opt-in on the
constructor/function argument and \std\code{cc} becomes transparent.}

For a better understanding, Tables
\ref{tab:binopresults1}--\ref{tab:binopresults2} present the result type of
binary \code{operator+} for different conversion strategies.
Note that \emph{the broadcast constructor has no influence on the results of
choice \ref{enum:binaryoptemplates}}.
This is why a simple broadcast constructor expecting a \code{value_type}
argument should be the more consistent choice for this scenario.

\begingroup
  \def\err{\textbf{\color{constants}ERROR}}
  \def\schar{\code{\color{types}schar}}
  \def\uchar{\code{\color{types}uchar}}
  \def\sshort{\code{\color{types}short}}
  \def\ushort{\code{\color{types}ushort}}
  \def\sint{\code{\color{types}int}}
  \def\uint{\code{\color{types}uint}}
  \def\slong{\code{\color{types}long}}
  \def\ulong{\code{\color{types}ulong}}
  \def\sllong{\code{\color{types}llong}}
  \def\ullong{\code{\color{types}ullong}}
  \def\float{\code{\color{types}float}}
  \def\double{\code{\color{types}double}}
  \def\bool{\code{\color{types}bool}}
  \def\Vschar{\simd[<\schar>]}
  \def\Vuchar{\simd[<\uchar>]}
  \def\Vsshort{\simd[<\sshort>]}
  \def\Vushort{\simd[<\ushort>]}
  \def\Vsint{\simd[<\sint>]}
  \def\Vuint{\simd[<\uint>]}
  \def\Vslong{\simd[<\slong>]}
  \def\Vulong{\simd[<\ulong>]}
  \def\Vsllong{\simd[<\sllong>]}
  \def\Vullong{\simd[<\ullong>]}
  \def\Vfloat{\simd[<\float>]}
  \def\Vdouble{\simd[<\double>]}
  \def\mca#1{\multicolumn{2}{c|}{#1}}
  \def\mcb#1{\multicolumn{3}{c|}{#1}}
  \def\LHS{\simd[<operand1>]}
  \def\LHSa{\mca{\LHS}}
  \def\LHSb{\mcb{\LHS}}
  \def\RHSa{\mca{\RHS}}
  \def\RHSb{\mcb{\RHS}}
  \def\erra{\mca{\err}}
  \def\errb{\mcb{\err}}
  \def\Rrr{\RHS (\err)}
  \newenvironment{TypeTable}[2]{
    \begin{table}[htbp]
      \caption{Binary operator results with #1 for operand 2}
      \label{#2}
      \smaller
      \begin{tabular}{>{\raggedright}p{0.47\textwidth}|c|c|c|}
        operand 1
        & \wgDocumentNumber{} (choice \ref{enum:valuepreserving})
        & choice \ref{enum:commontype}
        & choice \ref{enum:binaryoptemplates} \\\hline
        \gdef\RHS{#1}
  }{
      \end{tabular}
    \end{table}
  }
  \begin{TypeTable}{\Vsshort}{tab:binopresults1}
    \schar, \uchar, \sshort, \Vschar, \Vuchar, \Vsshort
    & \RHSb \\\hline

    \ushort, \uint, \slong, \ulong, \sllong, \ullong, \float, \double
    & \erra & \LHS \\\hline

    \sint
    & \Rrr & \err & \LHS \\\hline

    \bool
    & \err & \RHSa \\\hline

    \simd[<\ushort>], \simd[<\uint>], \simd[<\ulong>], \simd[<\ullong>]
    & \err & \LHSa \\\hline

    \simd[<\sint>], \simd[<\slong>], \simd[<\sllong>], \simd[<\float>],
    \simd[<\double>]
    & \LHSb
  \end{TypeTable}

  \begin{TypeTable}{\Vushort}{}
    \uchar, \ushort,
    \simd[<\uchar>], \simd[<\ushort>]
    & \RHSb \\\hline

    \slong, \ulong, \sllong, \ullong, \float, \double
    & \erra & \LHS \\\hline

    \sint, \uint
    & \Rrr & \err & \LHS \\\hline

    \schar, \sshort, \bool
    & \err & \RHSa \\\hline

    \simd[<\schar>], \simd[<\sshort>]
    & \err & \RHSa \\\hline

    \simd[<\sint>], \simd[<\uint>], \simd[<\slong>], \simd[<\ulong>],
    \simd[<\sllong>], \simd[<\ullong>], \simd[<\float>], \simd[<\double>]
    & \LHSb
  \end{TypeTable}

  \begin{TypeTable}{\Vuint}{}
    \uchar, \ushort, \uint,
    \simd[<\uchar>], \simd[<\ushort>], \simd[<\uint>]
    & \RHSb \\\hline

    \sint & \Rrr & \RHSa \\\hline

    \simd[<\slong>], \simd[<\ulong>], \simd[<\sllong>], \simd[<\ullong>],
    \simd[<\double>]
    & \LHSb \\\hline

    \slong, \ulong, \sllong, \ullong, \float, \double
    & \erra & \LHS \\\hline

    \schar, \sshort, \bool,
    \simd[<\schar>], \simd[<\sshort>], \simd[<\sint>],
    & \err & \RHSa \\\hline

    \simd[<\float>] & \err & \LHSa
  \end{TypeTable}

  \begin{TypeTable}{\Vulong}{}
    \uchar, \ushort, \uint, \ulong, \Vuchar, \Vushort, \Vuint, \Vulong
    & \RHSb \\\hline

    \sint & \Rrr & \RHSa \\\hline

    \schar, \sshort, \slong, \bool, \Vschar, \Vsshort, \Vsint, \Vslong
    & \err & \RHSa \\\hline

    \sllong, \Vsllong & \erra & \Vullong \\\hline

    \ullong & \RHS & \err & \Vullong \\\hline

    \Vullong & \mcb{\Vullong} \\\hline

    \float, \double & \erra & \LHS \\\hline

    \Vfloat, \Vdouble & \err & \LHSa
  \end{TypeTable}

  \begin{TypeTable}{\Vfloat}{}
    \schar, \uchar, \sshort, \ushort, \float, \Vschar, \Vuchar, \Vsshort, \Vushort,
    \Vfloat
    & \RHSb \\\hline

    \uint, \slong, \ulong, \sllong, \ullong, \bool, \Vsint, \Vuint, \Vslong,
    \Vulong, \Vsllong, \Vullong
    & \err & \RHSa \\\hline

    \sint & \Rrr & \RHSa \\\hline

    \double & \erra & \Vdouble \\\hline

    \Vdouble & \mcb{\Vdouble}
  \end{TypeTable}

  \begin{TypeTable}{\Vdouble}{tab:binopresults2}
    \schar, \uchar, \sshort, \ushort, \sint, \uint, \float, \double, \Vschar,
    \Vuchar, \Vsshort, \Vushort, \Vsint, \Vuint, \Vfloat, \Vdouble
    & \RHSb \\\hline

    \slong, \ulong, \sllong, \ullong, \bool, \Vslong, \Vulong, \Vsllong,
    \Vullong
    & \err & \RHSa
  \end{TypeTable}
\endgroup

\subsubsection{Suggested Polls}

\wgPoll{Base \simd conversion rules on the non-promoting common-type method
instead of value-preserving conversions (choice \ref{enum:commontype} in
\wgDocumentNumber).}
{&&&&}

\wgPoll{Base \simd binary operator result types on the non-promoting
common-type method while simplifying the broadcast constructor (choice
\ref{enum:binaryoptemplates} in \wgDocumentNumber).}
{&&&&}

\wgPoll{Remove broadcast ctor exceptions for \code{int} and \code{unsigned
int}, instead ensure \code{integral_constant}-like arguments work correctly.}
{&&&&}

\subsection{Keep or remove split and concat or parts of it}\label{sec:splitandconcat}
The TS includes the following functions for splitting \simd and \mask objects:
\begin{enumerate}
  \item\label{enum:split1} \stdx\code{split<N0, N1, N2, ...>(x)} returns a
    \std\code{tuple} of \simd/\mask (\code{x.size()} must be \code{N0 + N1 + N2
    ...})

  \item\label{enum:split2} \stdx\code{split<T>(x)} returns a \std\code{array<T,
    ...>} (\code{T} is a \simd/\mask and \code{x.size()} must be a multiple of
    \code{V::size()})

  \item\label{enum:split3} \stdx\code{split_by<N>(x)} returns a
    \std\code{array} of \simd/\mask (\code{x.size()} must be a multiple of
    \code{N})
\end{enumerate}

For concatenation the TS includes:
\begin{itemize}
  \item \stdx\code{concat(x, y, z)} returns a single \simd/\mask object
    containing the elements of \code{x}, \code{y}, and \code{z} (requires
    arguments to have the same element type)

  \item \stdx\code{concat(array_of_simd_or_mask)} returns a single \simd/\mask
    object containing the elements of the \simd/\mask objects in the
    \std\code{array}.
\end{itemize}

An obvious candidate for removal is the \code{concat(array)} overload, since
the same can be expressed using \std\code{apply}.
If it is not removed then why are there no additional overloads for all the
other tuple-like types?

The concatenation facility for \simd/\mask is useful and necessary for some of
the permutation examples presented in \cite{P2664R2}.
At this point there exists no good motivation for removal of \code{concat}
since we would expect a later paper to re-add this facility otherwise.

For \code{split} and \code{split_by} we should reconsider the usefulness of
each of the three overloads in light of the intent to add an ``extract''
function, which is supposed to return a slice of the input \simd/\mask as a
smaller \simd/\mask.
Such a function would be a replacement for the \ref{enum:split1}.~\code{split}
function.
The \ref{enum:split2}. and \ref{enum:split3}. function are equivalent:
\code{split_by<\MayBreak{}N>(\MayBreak{}T)} is the same as
\code{split<\MayBreak{}resize_simd_t<\MayBreak{}V::\MayBreak{}size() / N,
T>>(T)}; \code{split<U>(T)} is the same as
\code{split_by<\MayBreak{}T::\MayBreak{}size() /\MayBreak{}
U::\MayBreak{}size()\MayBreak{}>(T)}.
We could therefore consider reducing \code{split} to a single interface.

The use case I came across when wanting to use \code{split} is the splitting of
an “oversized” \simd into register-sized parts.
Example: \code{fixed_size_simd<float, 20>} could be made up of one AVX-512 and
one SSE register on an x86 target.
So I'd be interested in a simple interface of splitting
\code{fixed_size_simd<float, 20>} into \code{simd<float>} and
\code{simd<\MayBreak{}float, impl-defined-abi-tag>}%
\footnote{same as \code{fixed_size_simd<float, 4>} depending on
\sect{sec:simplifyfixedsize}}.
\stdx\code{split<16, 4>(x)} would achieve that.
But in generic code the derivation of these numbers is not trivial.

An extended \code{split<T>(x)} interface could instead do the following:
\code{split<simd<float>>(x)} returns a \code{tuple} of as many
\code{simd<float>} as \code{x.size()} allows plus an “epilogue” of
\code{simd<float, impl-defined-abi-tag} objects as are necessary to return all
elements of \code{x}.
Then \code{split<simd<float>>(fixed_size_simd<float, 20>)} returns
\begin{itemize}
  \item \code{tuple<simd<float>, resize_simd_t<4, simd<float>>>} with AVX-512,
  \item \code{tuple<simd<float>, simd<float>, resize_simd_t<4, simd<float>>>} with AVX, and
  \item \code{tuple<simd<float>, simd<float>, simd<float>, simd<float>, simd<float>>} with SSE.
\end{itemize}
If no “epilogue” is necessary, the return type could be an \code{array} instead
of a \code{tuple}, in which case the SSE case above would instead return
\begin{itemize}
  \item \code{array<simd<float>, 5>}.
\end{itemize}

More precise, the only remaining \code{split} function could be:
\begin{wgText}
\begin{itemdecl}
template<class V, class Abi>
  constexpr auto split(const simd<typename V::value_type, Abi>& x) noexcept;
\end{itemdecl}

\begin{itemdescr}
  % probably not necessary/helpful:
  %\pnum\mandates \tcode{V::size() <= simd_size_v<V::value_type, Abi>}.

  \pnum Let $N$ be \tcode{x.size() / V::size()}.

  \pnum\returns
  \begin{itemize}
    \item If \tcode{x.size() \% V::size() == 0}, an \tcode{array<V, $N$>} with
      the $i^\text{th}$ \simd element of the $j^\text{th}$ \tcode{array}
      element initialized to the value of the element in \tcode{x} with index
      \tcode{$i$ + $j$ * V::size()}.

    \item Otherwise, a \tcode{tuple} of $N$ objects of type \tcode{V} and one
      or more objects of types \tcode{resize_simd_t<Sizes, V>...} such that
      \tcode{(Sizes + ...)} is equal to \tcode{x.size() \% V::size()}.
      The $i^\text{th}$ \tcode{simd} element of the $j^\text{th}$ \tcode{tuple}
      element of type \tcode{V} is initialized to the value of the element in
      \tcode{x} with index \tcode{$i$ + $j$ * V::size()}.
      The $i^\text{th}$ \tcode{simd} element of the $j^\text{th}$ \tcode{tuple}
      with $j \ge N$ is initialized to the value of the element in \tcode{x}
      with index \tcode{$i$ + $N$ * V::size() +} sum of the first $j - N$
      values in the \tcode{Sizes} pack.
  \end{itemize}
\end{itemdescr}
\end{wgText}

\subsubsection{Renaming split and concat}

The names \code{split} and \code{concat} are very general.
We have naming precedent with \code{tuple_cat}.
If we follow the \code{tuple_cat} precedent the functions should be called
\code{simd_split} and \code{simd_cat}.

There is an alternative, where we envision making \std\code{concat} the name
for concatenation of all kinds of things in the standard library: simds,
strings, arrays, vectors, \ldots\footnote{all kinds of ranges?}.
The \code{split} interface, taking a template type to determine the split
granularity, is not as obvious to generalize.
\code{split<array<int, 4>>(array<int, 7>)}?
For strings the interface should likely look more like
\code{vector<string_view> split(string_view, string_view)}.

\subsubsection{Suggested Polls}

\wgPoll{Remove \code{concat(array<simd>)} overload.}
{&&&&}

\wgPoll{Replace all \code{split}/\code{split_by} functions by proposed
\code{split} function.}
{&&&&}

\wgPoll{Rename \code{split} to \code{simd_split} and \code{concat} to
\code{simd_cat}.}
{&&&&}


\subsection{Integration with ranges}\label{sec:ranges}
\code{simd} itself is not a container \cite{P0851R0}.
The value of a data-parallel object is not an array of elements but rather needs to be understood as a single opaque value that happens to have means for reading and writing element values.
I.e. \code{simd<int> x = \{\};} does not start the lifetime of \type{int} objects.
This implies that \code{simd} cannot model a contiguous range.
But \code{simd} can trivially model \code{random_access_range}.
However, in order to model \code{output_range}, the iterator of every non-const
\code{simd} would have to return an \code{element_reference} on dereference.
Without the ability of \code{element_reference} to decay to the element type
(similar to how arrays decay to pointers on deduction), I would prefer to
simply make \code{simd} model only \code{random_access_range}.

If \code{simd} is a range, then \std\code{vector<std::simd<float>> data} can
be flattened trivially via \code{data | std::views::join}.
This makes the use of ``arrays of \code{simd<T>}'' easier to integrate into
existing interfaces the expect ``array of \code{T}''.

I plan to pursue adding iterators and conversions to array and from
random-access ranges, specifically \code{span} with static extent, in a
follow-up paper.
I believe it is not necessary to resolve this question before merging
\code{simd} from the TS.

\subsection{Formatting support}\label{sec:formatting}
If \code{simd} \emph{is a} range, as suggested above and to be proposed in a
follow-up paper, then \code{simd} will automatically be formatted as a range.
This seems to be a good solution unless there is a demand to format \code{simd}
objects differently from \code{random_access_range}.

\subsection{std::hash}\label{sec:hash}

Is there a use case for \std\code{hash<simd<T>>}?
In other words, is there a use case for using \code{simd<T>} as a map key?
Recall that we do not consider \code{simd} to be a product type \cite{P0851R0}.
If there's no use case for hashing a \simd object as one, is there a use case
for multiple look-ups into a map, parallelizing the lookup as much as possible?

Consider a hash map with \code{int} keys and the task of looking up multiple
keys in arbitrary order (unordered).
In this case, one might want to pass a \code{simd<int>}, compute the hashes of
\code{simd<int>::\MayBreak{}size()} keys in parallel (using SIMD instructions), and
potentially determine the addresses (or offsets in contiguous memory) of the
corresponding values in parallel.
The value lookup could then use a SIMD gather instruction.

If we consider this use case important (or at least interesting), is
\std\code{hash<simd<T>>} the right interface to compute hashes element-wise?
After all, \code{simd} operations act element-wise unless strong hints in the
API suggest otherwise.

At this point I would prefer to wait for concrete use cases of hashing \simd
objects before providing any standard interface.
Specifically, at this point \emph{we do not want \std\code{hash} support for
\simd}.

\subsection{Freestanding SIMD}\label{sec:freestanding}
Should \code{simd} be enabled for freestanding?

It seems we maybe don't want to enable \simd for freestanding.
Kernel code typically wants to have a small state for more efficient
context switching.
Therefore floating-point and SIMD registers are not used.
However, we could limit \simd to integers and the scalar ABI for freestanding.
The utility of such a crippled \simd is highly questionable.

So the question we need answered is whether there are uses cases for
freestanding \simd, or whether \emph{all} freestanding code would outlaw \simd
anyway.
In other words, do we have or will we have users asking for \simd in
freestanding?

\subsection{Correct place for \code{simd} in the IS?}

While \code{simd} is certainly very important for numerics and therefore fits into the “Numerics library” clause, it is also more than that.
E.g. \code{simd} can be used for vectorization of text processing.
In principle \code{simd} should be understood similar to fundamental types.
Is the “General utilities library” clause a better place?
Or rename “Concurrency support library” to “Parallelism and concurrency support library” and put it there?
Alternatively, add a new library clause?

I am seeking feedback before making a recommendation.

\subsection{\code{element_reference} is overspecified}
\code{element_reference} is spelled out in a lot of detail.
It may be better to define its requirements in a list of requirements or a table instead.

This change is not reflected in the wording, pending encouragement from WG21 (mostly LWG).

\subsection{Remove \code{long double} from vectorizable types}

Rationale: TS experience. It's a headache.
It's not worth the specification and implementation effort.

\wgPoll{Remove \code{long double} from vectorizable types}
{&&&&}

\section{Wording: Add Section 9 of N4808 with modifications}\label{sec:wording}

The following section presents the wording to be applied against the \CC{}
working draft.

This wording overloads \code{operator?:} even though that's not possible (yet).
As long as we don't have the language feature for overloading \code{?:} the following needs to happen:
\begin{enumerate}
  \item Replace \code{operator?:} by \code{conditional_operator_impl}.
  \item Add a \std\code{conditional_operator(cond, a, b)} CPO that tries the following:
    \begin{itemize}
      \item If \code{conditional_operator_impl(cond, a, b)} can be found via ADL calls \code{conditional_operator_impl(cond, a, b)} unqualified, otherwise
      \item if \code{cond ? a : b} is well-formed, return its result, otherwise
      \item if \std\code{common_type_t<decltype(a), decltype(b)>} exists, cast \code{a} and \code{b} to this common type and apply \code{?:}.
    \end{itemize}
\end{enumerate}

\begin{wgText}[In {[version.syn]}, add]
  \begin{codeblock}
    #define __cpp_lib_simd YYYYMML // also in <simd>
  \end{codeblock}
\end{wgText}
Adjust the placeholder value as needed so as to denote this proposal's date of adoption.

\begin{wgText}[Add a new subclause after §28.8 {[numerics.numbers]}]
  \setcounter{WGClause}{28}
  \setcounter{WGSubSection}{8}
  \lstset{%
    columns=fullflexible,
    deletedelim=**[is]{|-}{-|},
    moredelim=[is][\color{white}\fontsize{0.1pt}{0.1pt}\selectfont{}]{|-}{-|}
  }
  \input{wording}
\end{wgText}

\end{document}
% vim: sw=2 sts=2 ai et tw=0
