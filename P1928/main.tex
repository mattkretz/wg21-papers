\newcommand\wgTitle{std::simd --- merge data-parallel types from the Parallelism TS 2}
\newcommand\wgName{Matthias Kretz <m.kretz@gsi.de>}
\newcommand\wgDocumentNumber{D1928R7}
\newcommand\wgGroup{LWG}
\newcommand\wgTarget{\CC{}26}
\newcommand\wgAcknowledgements{Thanks to Daniel Towner, Ruslan Arutyunyan, Jonathan Müller, Jeff Garland, and Nicolas Morales for discussions and/or pull requests on this paper.}

\usepackage{mymacros}
\usepackage{wg21}
\setcounter{tocdepth}{2} % show sections and subsections in TOC
\hypersetup{bookmarksdepth=5}
\usepackage{changelog}
\usepackage{underscore}
\usepackage{multirow}

\addbibresource{extra.bib}

\newcommand\simd[1][]{\type{basic\_simd#1}\xspace}
\newcommand\simdT{\type{basic\_simd<T>}\xspace}
\newcommand\valuetype{\type{value\_type}\xspace}
\newcommand\referencetype{\type{reference}\xspace}
\newcommand\simdcast{\code{simd\_cast}\xspace}
\newcommand\mask[1][]{\type{basic\_simd\_mask#1}\xspace}
\newcommand\maskT{\type{basic\_simd\_mask<T>}\xspace}
\newcommand\fixedsizeN{\type{simd\_abi::fixed\_size<N>}\xspace}
\newcommand\fixedsizescoped{\type{simd\_abi::fixed\_size}\xspace}
\newcommand\fixedsize{\type{fixed\_size}\xspace}
\newcommand\wglink[1]{\href{https://wg21.link/#1}{#1}}
\DeclareRobustCommand\simdabi{\code{simd\_abi\MayBreak::\MayBreak}}

\newcommand\nativeabi{\UNSP{native-abi}}
\newcommand\deducet{\UNSP{deduce-t}}
\newcommand\simdsizetype{\UNSP{simd-size-type}}
\newcommand\simdselect{\UNSP{simd-select-impl}}
\newcommand\maskelementsize{\UNSP{mask-element-size}}
\newcommand\integerfrom{\UNSP{integer-from}}
\newcommand\constexprwrapperlike{\UNSP{constexpr-wrapper-like}}

\renewcommand{\lst}[1]{Listing~\ref{#1}}
\renewcommand{\sect}[1]{Section~\ref{#1}}
\renewcommand{\ttref}[1]{Tony~Table~\ref{#1}}
\renewcommand{\tabref}[1]{Table~\ref{#1}}

\begin{document}
\selectlanguage{american}
\begin{wgTitlepage}
  After the Parallelism TS 2 was published in 2018, data-parallel types
  (\simdT) have been implemented and used.
  Now there is sufficient feedback to improve and merge Section 9 of the
  Parallelism TS 2 into the IS working draft.
\end{wgTitlepage}

\pagestyle{scrheadings}

\input{changelog}
\input{strawpolls}

\section{Introduction}
\cite{P0214R9} introduced \stdx\code{simd<T>} and related types and functions
into the Parallelism TS 2 Section 9.
The TS was published in 2018.
An incomplete and non-conforming (because P0214 evolved) implementation existed for the whole time P0214 progressed through the committee.
Shortly after the GCC 9 release, a complete implementation of Section 9 of the TS was made available.
Since GCC 11 a complete \code{simd} implementation of the TS is part of its standard library.

In the meantime the TS feedback progressed to a point where a merge should happen ASAP.
This paper proposes to merge only the feature-set that is present in the Parallelism TS 2.
(Note: The first revision of this paper did not propose a merge.)
If, due to feedback, any of these features require a change, then this paper (P1928) is the intended vehicle.
If a new feature is basically an addition to the wording proposed here, then it will progress in its own paper.

\subsection{Related papers}
\begin{description}
  \item[\wglink{P0350}] Before publication of the TS, SG1 approved \cite{P0350R0} which did not progress in time in LEWG to make it into the TS.
    \wglink{P0350} is moving forward independently.

  \item[\wglink{P0918}] After publication of the TS, SG1 approved \cite{P0918R2} which adds \code{shuffle}, \code{interleave}, \code{sum_to}, \code{multiply_sum_to}, and \code{saturated_simd_cast}.
    \wglink{P0918} will move forward independently.

  \item[\wglink{P1068}] R3 of the paper removed discussion/proposal of a \code{simd} based API because it was targeting \CC{}23 with the understanding of \code{simd} not being ready for \CC{}23.
    This is unfortunate as the presence of \code{simd} in the IS might lead to a considerably different assessment of the iterator/range-based API proposed in P1068.

  \item[\wglink{P0917}] The ability to write code that is generic wrt. arithmetic types and \code{simd} types is considered to be of high value (TS feedback).
    Conditional expressions via the \code{where} function were not all too well received.
    Conditional expressions via the conditional operator would provide a solution deemed perfect by those giving feedback (myself included).

  \item[draft on non-member {operator[]}] TODO

  \item[\wglink{P2600}] The fix for ADL is important to ensure the above two papers do not break existing code.

  \item[\wglink{P0543}] The paper proposing functions for saturation arithmetic expects \code{simd} overloads as soon as \code{simd} is merged to the IS.

  \item[\wglink{P0553}] The bit operations that are part of \CC{}20 expects \code{simd} overloads as soon as \code{simd} is merged to the IS.

  \item[\wglink{P2638}] Intel’s response to \wglink{P1915R0} for \code{std::simd}

  \item[\wglink{P2663}] \code{std::simd<std::complex<T>>}.

  \item[\wglink{P2664}] Permutations for \code{simd}.

  \item[\wglink{P2509}] \textcite{P2509R0} proposes a ``type trait to detect
    conversions between arithmetic-like types that always preserve the numeric
    value of the source object''. This matches the \textit{value-preserving}
    conversions the \code{simd} specification uses.
\end{description}
The papers \wglink{P0350}, \wglink{P0918}, \wglink{P2663}, \wglink{P2664}, and
the \code{simd}-based \wglink{P1068} fork currently have no shipping vehicle
and are basically blocked on this paper.

\section{Changes after TS feedback}\label{sec:changes}
\cite{P1915R0} (Expected Feedback from \code{simd} in the Parallelism TS 2) was published in 2019, asking for feedback to the TS.
I received feedback on the TS via the GitHub issue tracker, e-mails, and personal conversations.
There is also a lot of valuable feedback published in \wglink{P2638} ``Intel’s response to \wglink{P1915R0} for \std\code{simd}''.

\subsection{improve ABI tags}
Summary:
\begin{itemize}
  \item Change the default SIMD ABI tag to \simdabi\code{native<T>} instead of \simdabi\code{compatible<T>}.
  \item Change \simdabi\code{fixed_size} to not recommend implementations make it ABI compatible.
  \item At the Varna LEWG meeting it was decided to remove the \code{simd_abi}
    namespace and all standard ABI tags altogether.
    Rationale: The initial goal was to let \code{fixed_size} be equivalent to
    \stdx\simdabi\code{deduce_t}.
    This implies that \stdx\code{fixed_size_simd<T, N>} becomes the generic
    interface for deducing an efficient ABI tag.
    The next logical step is to give \code{fixed_size_simd} a shorter name and
    hide ABI tags.
    Consequently, \std\code{simd<T, N = \UNSP{native-size}>} is now and alias
    for \std\code{basic_simd<T, Abi>}.
\end{itemize}

For a discussion, see \wglink{P1928R3} Section 4.1 and \wglink{P1928R4} Section 5.2.

\subsection{\code{basic_simd_mask<sizeof, Abi>}}\label{sec:basicsimdmask}
Following the polls by LEWG in Issaquah 2023, \wglink{P1928R4} made mask types
interconvertible.
The next simplification was to make interconvertible types the same type
instead.
This is achieved by renaming the \stdx\code{simd_mask} class template to
\std\mask and changing the first template parameter from element type \code{T}
to \code{sizeof(T)}.
An alias \code{simd_mask<T, N> = basic_simd_mask<sizeof(T),
\UNSP{native-size}>} provides the simpler to use API.

The resulting mask types are explicitly convertible if the SIMD width is equal,
otherwise they are not convertible at all.
Note that for some target hardware the (explicitly) convertible masks are
convertible without any cost.
However, that's not the case for all targets, which is why the conversion is
still marked explicit.

\subsection{Simplify/generalize casts}\label{sec:casts}

For a discussion, see \wglink{P1928R3} Section 4.2.

Summary of changes wrt. TS:
\begin{enumerate}
  \item \code{simd<T0, A0>} is convertible to \code{simd<T1, A1>} if
    \code{simd_size_v<T0, A0> == simd_size_v<T1, A1>}.

  \item \code{simd<T0, A0>} is implicitly convertible to \code{simd<T1, A1>}
    if, additionally,
    \begin{itemize}
      \item the conversion \code{T0} to \code{T1} is value-preserving, and
      \item if both \code{T0} and \code{T1} are integral types, the integer
        conversion rank of \code{T1} is greater than or equal to the integer
        conversion rank of \code{T0}, and
      \item if both \code{T0} and \code{T1} are floating-point types, the
        floating-point conversion rank of \code{T1} is greater than or equal to
        the floating-point conversion rank of \code{T0}.
    \end{itemize}


  \item \code{simd_mask<T0, A0>} is convertible to \code{simd_mask<T1, A1>} if
    \code{simd_size_v<T0, A0> == simd_size_v<T1, A1>}.

  \item \code{simd_mask<T0, A0>} is implicitly convertible to
    \code{simd_mask<T1, A1>} if, additionally, \code{sizeof(T0) ==
    sizeof(T1)}.
    (This point is irrelevant if \sect{sec:basicsimdmask} is accepted.)

  \item \code{simd<T0, A0>} can be \code{bit_cast}ed to \code{simd<T1, A1>} if
    \code{sizeof(simd<T0, A0>) == sizeof(simd<T1, A1>)}.

  \item \code{simd_mask<T0, A0>} can be \code{bit_cast}ed to \code{simd_mask<T1, A1>} if
    \code{sizeof(simd_mask<T0, A0>) == sizeof(simd_mask<T1, A1>)}.
\end{enumerate}

\subsection{Add \code{simd_mask} generator constructor}

This constructor was added:
\begin{wgText}
\begin{itemdecl}
template<class G> simd_mask(G&& gen) noexcept;
\end{itemdecl}
\end{wgText}

For a discussion, see \wglink{P1928R3} Section 4.3.

\subsection{Default load/store flags to \code{element_aligned}}

Different to the TS, load/store flags default to \code{element_aligned}.
For a discussion, see \wglink{P1928R3} Section 4.4.

\subsection{Contiguous iterators for loads and stores}\label{sec:contiguousItLoadStore}

Different to the TS, loads and stores use \code{contiguous_iterator} instead of pointers.
For a discussion, see \wglink{P1928R3} Section 4.5.

\subsection{\code{constexpr} everything}
The merge adds \code{constexpr} to all functions.
For a discussion, see \wglink{P1928R3} Section 4.6.

\subsection{Specify \code{simd::size} as \code{integral_constant}}

Different to the TS, this paper uses a static data member \code{size} of type
\std\code{integral_constant<\MayBreak\std{}size_t, N>} in \simd and \mask.
For a discussion, see \wglink{P1928R3} Section 4.7.

\subsection{Replace \code{where} facilities}

The following load/store overloads have been added as a replacement for
\stdx\code{where_expression::copy_from} and \stdx\code{const_where_expression::copy_to}:
\begin{itemize}
    \raggedright
  \item \code{simd::simd(contiguous_iterator, const mask_type\&, Flags = \{\})} (selected elements are copied from given range, otherwise use value-initialization)
  \item \code{simd::copy_from(contiguous_iterator, const mask_type\&, Flags = \{\})} (selected elements are copied from given range)
  \item \code{simd::copy_to(contiguous_iterator, const mask_type\&, Flags = \{\})} (selected elements are copied to given range)
  \item \code{simd_mask::simd_mask(contiguous_iterator, const mask_type\&, Flags = \{\})} (selected elements are copied from given range, otherwise use value-initialization)
  \item \code{simd_mask::copy_from(contiguous_iterator, const mask_type\&, Flags = \{\})} (selected elements are copied from given range)
  \item \code{simd_mask::copy_to(contiguous_iterator, const mask_type\&, Flags = \{\})} (selected elements are copied to given range)
\end{itemize}

The \code{reduce}, \code{hmin}, and \code{hmax} overloads with
\code{const_where_expression} argument have been replaced by overloads with
\simd and \mask arguments.

The following operators were added to \mask:
\begin{itemize}
    \raggedright
  \item \code{basic_simd_mask::operator basic_simd<U, A>() const noexcept}
  \item \code{\textit{simd-type} basic_simd_mask::operator+() const noexcept}
  \item \code{\textit{simd-type} basic_simd_mask::operator-() const noexcept}
  \item \code{\textit{simd-type} basic_simd_mask::operator\~{}() const noexcept}
\end{itemize}

The following hidden friends were added to \mask:
\begin{itemize}
    \raggedright
  \item \code{basic_simd_mask \simdselect(const basic_simd_mask\&, const basic_simd_mask\&, const basic_simd_mask\&) noexcept}
  \item \code{basic_simd_mask \simdselect(const basic_simd_mask\&, bool, bool) noexcept}
  \item \code{simd<\UNSP{non-promoting-common-type}<T0, T1> \simdselect(const basic_simd_mask\&,
    const T0\&, const T1\&) noexcept}
\end{itemize}

The following hidden friend was added to \simd:
\begin{itemize}
    \raggedright
  \item \code{basic_simd \simdselect(const mask_type\& mask, const basic_simd\& a, const basic_simd\& b) noexcept}
\end{itemize}

Instead of \code{\simdselect} we would have preferred to overload
\code{operator?:} but that requires a language change first.
As long as we don't have the language feature for overloading \code{?:},
generic code must use an inferior function instead.
Knowing that other libraries would benefit from an overloadable
\code{operator?:} \wglink{P1928R4} proposed a \code{std::conditional_operator}
CPO that 3rd-party libraries could have extended.
However, the use of a function (or CPO) instead of overloading
\code{operator?:} cannot keep the semantics of \code{?:}, which doesn't
evaluate an expression unless its result is actually needed.
For a function, we cannot pass expressions but only their results.
Relevant papers: \cite{P0927R2}, \cite{D0917}.

Therefore LEWG decided in Varna to define a \std\code{simd_select} function
instead of a general CPO, with the following goals:
\begin{itemize}
  \item User's shouldn't extend this.
  \item Make it “value based”, i.e. don't bother about references for non-simd
    arguments.
\end{itemize}

\subsection{Make use of \code{int} and \code{size_t} consistent}\label{sec:simdsizetype}

Different to the TS, this paper uses \code{\simdsizetype} for
\begin{itemize}
  \item the SIMD width (number of elements),
  \item the subscript operator arguments, and
  \item the \mask reductions that return an integral value.
\end{itemize}

Alignments and values identifying a \code{sizeof} still use \code{size_t}.

The type \simdsizetype{} is an exposition-only alias for a signed integer type.
I.e. the implementation is free to choose any signed integer type.

The rationale given in the LEWG discussion was a desire to avoid type
conversions when using the result of a \mask reduction as subscript argument.
Since functions like \code{__builtin_popcount} in GCC typically return
\code{int}, the natural choice is to stick with that type and make subscript
arguments use the same type.
Since the SIMD width is also sometimes used in expressions in the subscript
argument, the SIMD width should also have the same type.

\subsection{Clean up math function overloads}
The wording that produces \simd overloads misses a few cases and leaves room for ambiguity.
There is also no explicit mention of integral overloads that are supported in \code{<cmath>} (e.g. \std\code{cos(1)} calling \std\code{cos(double)}).
At the very least, \std\code{abs(\simd<\textit{signed-integral}>)} should be specified.

Also, from implementation experience, ``undefined behavior'' for domain, pole,
or range error is unnecessary.
It could either be an unspecified result or even match the expected result of
the function according to Annex F in the C standard.
The latter could possibly be a recommendation, i.e. QoI.
The intent is to avoid \code{errno} altogether, while still supporting
floating-point exceptions (possibly depending on compiler flags).

This needs more work and is not reflected in the wording at this point.

%Wording idea:
%\begin{wgText}
%  \setcounter{Paras}{2}
%  \pnum
%  For each function with at least one parameter of type
%  \term{floating-point-type} other than \tcode{abs}, the implementation also
%  provides additional overloads sufficient to ensure that:
%  \begin{enumerate}
%    \item If at least one argument has a type that is a specialization of \tcode{simd}, then,
%      \begin{itemize}
%        \item if any two arguments are specializations of \tcode{simd} with
%          different width, then overload resolution does not result in a usable
%          candidate ([over.match.general]) from the overloads provided by the
%          implementation; otherwise
%        % now all simd arguments have equal width, or arguments are non-simd
%        \item every argument that is a specialization of \tcode{simd}
%      \end{itemize}
%      if every argument corresponding to a \term{floating-point-type} parameter
%      has arithmetic type or is a specialization of \tcode{simd}, then every
%      such
%      argument is effectively cast to the floating-point type with the greatest
%      floating-point conversion rank and greatest floating-point conversion
%      subrank among the types of all such arguments, where arguments of integer
%      type are considered to have the same floating-point conversion rank as
%      \tcode{double}.
%
%    \item Otherwise, if every argument corresponding to a
%      \term{floating-point-type} parameter has arithmetic type, then every such
%      argument is effectively cast to the floating-point type with the greatest
%      floating-point conversion rank and greatest floating-point conversion
%      subrank among the types of all such arguments, where arguments of integer
%      type are considered to have the same floating-point conversion rank as
%      \tcode{double}.
%      If no such floating-point type with the greatest rank and subrank exists,
%      then overload resolution does not result in a usable candidate
%      ([over.match.general]) from the overloads provided by the implementation.
%  \end{enumerate}
%\end{wgText}

\subsection{Add lvalue-qualifier to non-const subscript}\label{sec:lvalue-subscript}
The \code{operator[]} overloads of \simd and \mask returned a
proxy reference object for non-\code{const} objects and the \code{value_type}
for \code{const} objects.
This made expressions such as \code{(x * 2)[0] = 1} well-formed.
However, assignment to temporaries can only be an error in the code (or code obfuscation).
Both \code{operator[]} overloads should be lvalue-ref qualified to make
\code{(x * 2)[0]} pick the const overload, which returns a prvalue that is not
assignable.

\subsection{Rename \code{simd_mask} reductions}
Summary:
\begin{itemize}
  \item The function \stdx\code{some_of} was removed.
  \item The function \stdx\code{popcount} was renamed to \std\code{reduce_count}.
  \item The function \stdx\code{find_first_set} was renamed to \std\code{reduce_min_index}.
  \item The function \stdx\code{find_last_set} was renamed to \std\code{reduce_max_index}.
\end{itemize}

For a discussion of this topic see \wglink{P1928R3} Section 5.2.

\subsection{Rename \code{hmin} and \code{hmax}}\label{sec:hminhmax}
The functions \code{hmin(simd)} and \code{hmax(simd)} were renamed to
\code{reduce_min} and \code{reduce_max} according to guidance from LEWG in
Varna 2023.

\subsection{Added constraints on operators and functions to match their underlying element types}

Previously some operators (e.g., \code{operator<}) and functions which relied on
some property of the element type (e.g., \tcode{min} relies on ordering)
were unconstrained. Operations which were not permitted on individual elements
were still available in the overload set for \simd objects of those types.
Constraints have been added where necessary to remove such operators and
functions from the overload set where they aren't supported.


\subsection{Rename alignment flags and extend load/store flags for opt-in to conversions}\label{sec:renameandextendflags}

For some discussion, see \wglink{P1928R3} Section 5.4.

In addition to the TS, the load/store flag mechanism is extended to enable combination of flags.
The new flag enables conversions that are not \emph{value-preserving} on loads and stores.
Without the flag only \emph{value-preserving} conversions are allowed.

\subsubsection{Historical context}
The existing flags
\begin{itemize}
  \item \stdx\code{element_aligned},
  \item \stdx\code{vector_aligned}, and
  \item \stdx\code{overaligned<N>}
\end{itemize}
had no need for combining since they are exclusive.
Therefore, the TS included no such mechanism.
We should include a flag combining mechanism in any case, in order to allow
extensions without breaking implementations.
For reference, the original proposal \cite{N4184, §6.2} included a
\code{streaming} flag and a flag to assist in emitting prefetch instructions.
I implemented these flags in the Vc library more than 10 years ago.
For sake of proving the viability without too much complexity, SG1 asked to
reduce load store flags to what we finally shipped in the TS.

\subsubsection{Renaming alignment flags}
Now that the alignment flags move from \stdx{} to \std{}, we need to reconsider their names.
See \tabref{tab:alignmentnames} for a list of names that were considered.
\newcommand\simdflag[1]{
  \std\code{simd_#1},\newline
  \std\code{simd_flag_#1},\newline
  \std\code{simd_copy_#1},\newline
  \std\code{loadstore_#1},\newline
  \std\code{simd_flags\MayBreak{}::\MayBreak{}#1}
}
\newcommand\simdflagpref[1]{
  \std\code{loadstore_#1}
}
\begin{table}[hbtp]
  \caption{Name alternatives for alignment flags}
  \label{tab:alignmentnames}
  \smaller
\begin{tabular}{p{0.25\textwidth}p{0.35\textwidth}p{0.3\textwidth}}
  TS name & Ideas & Preference \\\hline

  \stdx\code{element_aligned}
  & \std\code{default_simd_flags},\newline
    \simdflag{element_aligned},\newline
    \simdflag{unaligned},\newline
    \simdflag{default}
  & \simdflagpref{default} \\\hline

  \stdx\code{vector_aligned}
  & \simdflag{aligned}
  & \simdflagpref{aligned} \\\hline

  \stdx\code{overaligned<N>}
  & \std\code{overaligned<N>},\newline
    \simdflag{overaligned<N>}
  & \simdflagpref{overaligned<N>} \\\hline

  ---
  & \simdflag{convert},\newline
    \simdflag{cvt_any},\newline
    \simdflag{any_cvt}
  & \simdflagpref{convert}
\end{tabular}
\end{table}
On my choices:
\begin{description}
  \item[\simdflagpref{default}] This is the default.
    There is no need to say anything about alignment.
    Alignment follows the assumptions of the rest of \CC{}; there's nothing
    special.
    It is useful to have a name for the default.
    Some generic programming patterns need to decide on default vs. aligned
    depending on template parameters.

  \item[\simdflagpref{aligned}] This flags says that the memory pointed to by
    the iterator follows stricter alignment requirements.
    Specifically it follows \code{memory_alignment_v<T, U>} (\code{T} is the
    \simdT element type and \code{U} is the array element type).
    We should consider renaming \code{memory_alignment(_v)} to
    \code{simd_alignment(_v)} or \code{simd_loadstore_alignment(_v)}.

  \item[\simdflagpref{overaligned<N>}] This flags says that the memory pointed
    to by the iterator is aligned by \code{N} bytes.

  \item[\simdflagpref{convert}] This flag allows all conversions on load/store,
    in contrast to only \emph{value-preserving} conversions.
    It doesn't enable \emph{all} conversions, because value-preserving
    conversions are always enabled.
    But I cannot think of a more descriptive name that isn't at the same time
    also more confusing (``convert more'', ``convert anything'').
\end{description}

Note that the wording also allows additional implementation-defined load and
store flags.

The trait \code{is_simd_flag_type} has been removed because the flag parameter
is now constrained via the \code{loadstore_flag} class template.

As a result, executing a not-value-preserving store on 16-Byte aligned memory now reads as:
\begin{tabular}{p{.48\textwidth}|p{.48\textwidth}}
TS & \wgDocumentNumber \\\hline%
\smaller%
\begin{lstlisting}
float *addr = ...;
void f(stdx::native_simd<double> x) {
  x.copy_to(addr, stdx::overaligned<16>);
}

\end{lstlisting}
&\smaller%
\begin{lstlisting}
float *addr = ...;
void f(std::simd<double> x) {
  x.copy_to(addr, std::loadstore_convert |
                  std::loadstore_overaligned<16>);
}
\end{lstlisting}
\end{tabular}

\subsection{Reduce overloads and rename split and concat}\label{sec:splitandconcat}

The \stdx\code{concat(array)} overload was removed in favor of using
\std\code{apply}.
The remaining \stdx\code{concat} function was renamed to \std\code{simd_cat}
following the \std\code{tuple_cat} naming precedent.

The two \stdx\code{split} and one \stdx\code{split_by} functions from the TS
were consolidated into a single \std\code{simd_split} function.
The design intent for the \code{simd_split} function is to support the use case
of splitting an “oversized” \simd into register-sized parts.
Example: \code{simd<float, 20>} could be made up of one AVX-512 and one SSE
register on an x86 target.
\code{simd_split} is a simple interface for splitting \code{simd<float, 20>}
into \code{simd<float>} and \code{basic_simd<\MayBreak{}float,
\UNSP{impl-defined-abi-tag}>}\footnote{same as \code{simd<float, 4>}.}.

\std\code{simd_split<T>(x)} does the following:
\code{simd_split<simd<float>>(x)} returns a \code{tuple} of as many
\code{simd<float>} as \code{x.size()} allows plus an “epilogue” of one
\code{simd<float, impl-defined-abi-tag} object as necessary to return all
elements of \code{x}.
If no “epilogue” is necessary, the return type is an \code{array} instead of a
\code{tuple}.
Then \code{simd_split<simd<float>>(simd<float, 20>)} returns
\begin{itemize}
  \item \code{tuple<simd<float>, simd<float, 4>>} with AVX-512,
  \item \code{tuple<simd<float>, simd<float>, simd<float, 4>>} with AVX, and
  \item \code{array<simd<float>, 5>} with SSE.
\end{itemize}
The \code{simd_split} function is overloaded for \simd and \mask.

\subsubsection{Renaming split and concat}

The names \code{split} and \code{concat} are very general.
We have naming precedent with \code{tuple_cat}.
If we follow the \code{tuple_cat} precedent the functions should be called
\code{simd_split} and \code{simd_cat}.

There is an alternative, where we envision making \std\code{concat} the name
for concatenation of all kinds of things in the standard library: simds,
strings, arrays, vectors, \ldots\footnote{all kinds of ranges?}.
The \code{split} interface, taking a template type to determine the split
granularity, is not as obvious to generalize.
\code{split<array<int, 4>>(array<int, 7>)}?
For strings the interface should likely look more like
\code{vector<string_view> split(string_view, string_view)}.

\subsubsection{Suggested Polls}

\wgPoll{Remove \code{concat(array<simd>)} overload.}
{&&&&}

\wgPoll{Replace all \code{split}/\code{split_by} functions by proposed
\code{split} function.}
{&&&&}

\wgPoll{Rename \code{split} to \code{simd_split} and \code{concat} to
\code{simd_cat}.}
{&&&&}


\subsection{Remove \code{int} exception from broadcast conversion rules}\label{sec:broadcastexception}

LEWG discussed conversions in Issaquah 2023 and Varna 2023.
\wglink{P1928R4} Section 5.4 presented alternatives and their implications.
LEWG decided in Varna to stick with value-preserving conversions as used in the
TS.
However, the exception for \code{int} and \code{unsigned int} conversions to
\code{simd} were removed.
Instead, \code{integral_constant}-like arguments, which will hopefully be
available as literals in \CC{}26, will be supported and their values (instead
of types) determine whether the conversion is allowed.

\subsection{Remove \code{long double} from vectorizable types}

Rationale: TS experience. It's a headache.
It's not worth the specification and implementation effort.

\subsection{Increase minimum supported width to 64}

The TS required a minimum of 32, with \CC{}26 the minimum will be 64.

Rationale: AVX-514 \code{simd<char>::size() == 64}.
And also \code{long double} is not a vectorizable type anymore.

\subsection{No std::hash<simd>}\label{sec:hash}

No support for \std\code{hash<simd<T>>} was added.

Rationale:
Is there a use case for \std\code{hash<simd<T>>}?
In other words, is there a use case for using \simdT as a map key?
Recall that we do not consider \simdT to be a product type \cite{P0851R0}.
If there's no use case for hashing a \simdT object as one, is there a use case
for multiple look-ups into a map, parallelizing the lookup as much as possible?

Consider a hash map with \code{int} keys and the task of looking up multiple
keys in arbitrary order (unordered).
In this case, one might want to pass a \code{simd<int>}, compute the hashes of
\code{simd<int>::\MayBreak{}size()} keys in parallel (using SIMD instructions), and
potentially determine the addresses (or offsets in contiguous memory) of the
corresponding values in parallel.
The value lookup could then use a SIMD gather instruction.

If we consider this use case important (or at least interesting), is
\std\code{hash<simd<T>>} the right interface to compute hashes element-wise?
After all, \code{simd} operations act element-wise unless strong hints in the
API suggest otherwise.

At this point we prefer to wait for concrete use cases of hashing \simd objects
before providing any standard interface.
Specifically, at this point \emph{we do not want \std\code{hash} support for
\simd}.

\subsection{No freestanding SIMD}\label{sec:freestanding}

\code{simd} will not be enabled for freestanding.

Kernel code typically wants to have a small state for more efficient
context switching.
Therefore floating-point and SIMD registers are not used.
However, we could limit \simd to integers and the scalar ABI for freestanding.
The utility of such a crippled \simd is highly questionable.
Note that freestanding is just the baseline requirement and embedded targets
are still free to add \code{simd} support.

\section{Open questions / Outlook}
\subsection{Correct place for \code{simd} in the IS?}

While \code{simd} is certainly very important for numerics and therefore fits into the “Numerics library” clause, it is also more than that.
E.g. \code{simd} can be used for vectorization of text processing.
In principle \code{simd} should be understood similar to fundamental types.
Is the “General utilities library” clause a better place?
Or rename “Concurrency support library” to “Parallelism and concurrency support library” and put it there?
Alternatively, add a new library clause?

I am seeking feedback before making a recommendation.

\subsection{\code{element_reference} is overspecified}
\code{element_reference} is spelled out in a lot of detail.
It may be better to define its requirements in a list of requirements or a table instead.

This change is not reflected in the wording, pending encouragement from WG21 (mostly LWG).

\subsection{Implementation hints}\label{sec:implnote}
We should consider the addition of a note recommending implementations let
\simd and \mask operations behave like operations of built-in types.
Specifically, built-in operators are never function calls\footnote{The
exception may be soft-float?}.
(cf. \href{https://gcc.gnu.org/PR108030}{GCC PR108030})

\subsection{Integration with ranges}\label{sec:ranges}
\code{simd} itself is not a container \cite{P0851R0}.
The value of a data-parallel object is not an array of elements but rather needs to be understood as a single opaque value that happens to have means for reading and writing element values.
I.e. \code{simd<int> x = \{\};} does not start the lifetime of \type{int} objects.
This implies that \code{simd} cannot model a contiguous range.
But \code{simd} can trivially model \code{random_access_range}.
However, in order to model \code{output_range}, the iterator of every non-const
\code{simd} would have to return an \code{element_reference} on dereference.
Without the ability of \code{element_reference} to decay to the element type
(similar to how arrays decay to pointers on deduction), I would prefer to
simply make \code{simd} model only \code{random_access_range}.

If \code{simd} is a range, then \std\code{vector<std::simd<float>> data} can
be flattened trivially via \code{data | std::views::join}.
This makes the use of ``arrays of \code{simd<T>}'' easier to integrate into
existing interfaces the expect ``array of \code{T}''.

I plan to pursue adding iterators and conversions to array and from
random-access ranges, specifically \code{span} with static extent, in a
follow-up paper.
I believe it is not necessary to resolve this question before merging
\code{simd} from the TS.

\subsection{Formatting support}\label{sec:formatting}
If \code{simd} \emph{is a} range, as suggested above and to be proposed in a
follow-up paper, then \code{simd} will automatically be formatted as a range.
This seems to be a good solution unless there is a demand to format \code{simd}
objects differently from \code{random_access_range}.

\section{Changes after LEWG approval}

\subsection{\code{simd_select} overload set}\label{sec:simdselectwording}

\wglink{P1928R6} presented the following overload set of the exposition-only
hidden friend \code{\simdselect}:
\begin{codeblock}
template<class T, class Abi> class basic_simd {
  // [...]
  friend constexpr basic_simd @\simdselect@(
    const mask_type&, const basic_simd&, const basic_simd&) noexcept; // #1
};
// [...]
template<size_t Bytes, class Abi> class basic_simd_mask {
  // [...]
  friend constexpr basic_simd_mask @\simdselect@(
    const basic_simd_mask&, const basic_simd_mask&, const basic_simd_mask&) noexcept; // #2
  friend constexpr basic_simd_mask @\simdselect@(
    const basic_simd_mask&, bool, bool) noexcept; // #3
  template <class T0, class T1>
    friend constexpr basic_simd<@\seebelow@, Abi>
      @\simdselect@(const basic_simd_mask&, const T0&, const T1&) noexcept; // #4
};
\end{codeblock}

Given \code{std::simd_select(std::simd<double, 4>() == 0, 1, 2)}, the compiler
would choose overload \code{\#3} because \code{int} is convertible to
\code{bool} and \code{\#4} is constrained, requiring
\code{sizeof(\UNSP{non-promoting-common-type}<T0, T1>) == sizeof(double)}.
That does not match the design intent.
The intent was for non-boolean and non-simd arguments to pick overload
\code{\#4} or fail to compile.
This can be achieved either by replacing \code{bool} with a type that is
convertible from \code{bool} only, or via \code{same_as<bool> auto} instead of
\code{bool}.
The former leads to puzzling error messages, because overload \code{\#4} is not
mentioned in the resulting diagnostics.
The latter will lead to a listing of all candidates and the reason why they
were not viable.

Therefore, the wording for overload \code{\#3} was changed to say
\code{same_as<bool> auto} instead of \code{bool}.


\subsection{Tighten \code{simd_split} specification}\label{sec:bettersimdsplitwording}

The reviewed wording (Varna 2023) for \code{simd_split} left the “epilogue”
\simd object(s) unspecified.
A user of \code{simd_split} therefore would have to cope with implementations
returning one or more \simd objects for the otherwise same input parameters.
Consider the case
\code{simd_split\MayBreak{}<\MayBreak{}simd\MayBreak{}<\MayBreak{}int, 8>>(x)}
with \code{simd\MayBreak{}<\MayBreak{}int, 15>}.
One implementation might return
\\\code{tuple<simd<int, 8>, simd<int, 7>>}\\
while another implementation returns
\\\code{tuple<simd<int, 8>, simd<int, 4>, simd<int, 2>, simd<int, 1>>}\\
and yet another could choose to return
\\\code{tuple<simd<int, 8>, simd<int, 4>, simd<int, 3>>}.
There are good reasons for either one of these.
However, letting the implementation choose which one is best doesn't really
help the user of the interface.
Therefore, the wording was modified to return a single “epilogue” \simd object.
In the example above, the user is thus returned a \code{simd<int, 7>} on every
implementation and can choose to apply another \code{simd_split} to arrive at
\code{tuple<simd<int, 4>, simd<int, 3>>} and so on.

\subsection{Remove precondition on mask reductions}\label{sec:removemaskreductionprecondition}

As directed by LEWG, the precondition on \code{reduce_min_index} and
\code{reduce_max_index} was removed from the latest wording.
This required a specification of the return value for the missing case.
The following results were chosen:
\begin{enumerate}
  \item \code{reduce_min_index(simd_mask<int, 4>(false))} returns \code{4} (the SIMD width)

  \item \code{reduce_max_index(simd_mask<int, 4>(false))} returns \code{-1}

  \item \code{reduce_min_index(false)} returns \code{1}

  \item \code{reduce_max_index(false)} returns \code{-1}
\end{enumerate}

\subsubsection{New information}
It was always stated in LEWG discussions that removal of the precondition has
no performance cost on modern processors.
This is true for some cases but not in general.
Consider \code{reduce_min_index(simd_mask<int, 4>(...))}: A reasonable x86
implementation will either already use a bit-mask (AVX512) or turn the
vector-mask into a bit-mask (e.g. \code{movmskps}).
\std\code{countr_zero} can be used to determine the position of the first
non-zero bit in the bit-mask.
If, however, the given mask was empty, then \code{countr_zero} will return the
width of the given integer type, typically \code{32}.
The correct answer for \code{reduce_min_index} needs to be \code{4}, though.
So a fix-up is required.
This could either be a branch on \code{32} or the implementation can
unconditionally set the bit at index 4 before calling \code{countr_zero}.
In any case, code size increases.
In the branch-free implementation, the latency of the \code{reduce_min_index}
call unconditionally increases by one clock cycle.

While avoiding UB is nice, the usefulness of returning \mask\code{::size()} or
\code{-1} is questionable.
How can these numbers be used other than for branching?
Isn't it better to branch on \code{none_of(mask)} before calling
\code{reduce_min_index}?

\subsubsection{Alternative}
Instead of UB, the reduction functions could also return an unspecified value.
And maybe debug builds can be encouraged to diagnose calls with an empty
mask\footnote{I guess Contracts would only trigger for a real precondition,
a.k.a. UB?}.
In order to follow the “don't pay for whay you don't use” guideline, the
precondition should be restored.

\section{Wording: Add Section 9 of N4808 with modifications}\label{sec:wording}

The following section presents the wording to be applied against the \CC{}
working draft.

This wording overloads \code{operator?:} even though that's not possible (yet).
As long as we don't have the language feature for overloading \code{?:} the following needs to happen:
\begin{enumerate}
  \item Replace \code{operator?:} by \code{conditional_operator_impl}.
  \item Add a \std\code{conditional_operator(cond, a, b)} CPO that tries the following:
    \begin{itemize}
      \item If \code{conditional_operator_impl(cond, a, b)} can be found via ADL calls \code{conditional_operator_impl(cond, a, b)} unqualified, otherwise
      \item if \code{cond ? a : b} is well-formed, return its result, otherwise
      \item if \std\code{common_type_t<decltype(a), decltype(b)>} exists, cast \code{a} and \code{b} to this common type and apply \code{?:}.
    \end{itemize}
\end{enumerate}

\begin{wgText}[In {[version.syn]}, add]
  \begin{codeblock}
    #define __cpp_lib_simd YYYYMML // also in <simd>
  \end{codeblock}
\end{wgText}
Adjust the placeholder value as needed so as to denote this proposal's date of adoption.

\begin{wgText}[Add a new subclause after §28.8 {[numerics.numbers]}]
  \setcounter{WGClause}{28}
  \setcounter{WGSubSection}{8}
  \lstset{%
    columns=fullflexible,
    deletedelim=**[is]{|-}{-|},
    moredelim=[is][\color{white}\fontsize{0.1pt}{0.1pt}\selectfont{}]{|-}{-|}
  }
  \input{wording}
\end{wgText}

\end{document}
% vim: sw=2 sts=2 ai et tw=0
