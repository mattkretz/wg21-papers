\newcommand\wgTitle{Restore \code{simd::vec} broadcast from \code{int}}
\newcommand\wgName{Matthias Kretz <m.kretz@gsi.de>}
\newcommand\wgDocumentNumber{P3844R1}
\newcommand\wgGroup{LEWG}
\newcommand\wgTarget{\CC{}26}
%\newcommand\wgAcknowledgements{Daniel Towner and Ruslan Arutyunyan contributed to this paper via discussions / reviews. Thanks also to Jeff Garland for reviewing.}

\usepackage{mymacros}
\usepackage{wg21}
\setcounter{tocdepth}{2} % show sections and subsections in TOC
\hypersetup{bookmarksdepth=5}
\usepackage{changelog}
\usepackage{underscore}
\usepackage{multirow}
\usepackage{vectorpictures}

\addbibresource{extra.bib}

\newcommand\simd[1][]{\type{ba\-sic\_vec#1}\xspace}
\newcommand\simdT{\type{ba\-sic\_vec\MayBreak<\MayBreak{}T>}\xspace}
\newcommand\valuetype{\type{val\-ue\_type}\xspace}
\newcommand\referencetype{\type{ref\-er\-ence}\xspace}
\newcommand\mask[1][]{\type{ba\-sic\_mask#1}\xspace}
\newcommand\maskT{\type{ba\-sic\_mask\MayBreak<\MayBreak{}T>}\xspace}
\newcommand\wglink[1]{\href{https://wg21.link/#1}{#1}}

\newcommand\nativeabi{\UNSP{native-abi}}
\newcommand\deducet{\UNSP{deduce-t}}
\newcommand\simdsizev{\UNSP{simd-size-v}}
\newcommand\simdsizetype{\UNSP{simd-size-type}}
\newcommand\simdselect{\UNSP{simd-select-impl}}
\newcommand\maskelementsize{\UNSP{mask-element-size}}
\newcommand\integerfrom{\UNSP{integer-from}}
\newcommand\constexprwrapperlike{\UNSP{constexpr-wrapper-like}}
\newcommand\convertflag{\UNSP{convert-flag}}
\newcommand\alignedflag{\UNSP{aligned-flag}}
\newcommand\overalignedflag{\UNSP{overaligned-flag}}
\newcommand\reductionoperation{\UNSP{reduction-binary-operation}}
\newcommand\simdfloatingpoint{\UNSP{simd-floating-point}}
\newcommand\multisimdfloatingpoint{\UNSP{multi-arg-simd-floating-point}}

\renewcommand{\lst}[1]{Listing~\ref{#1}}
\renewcommand{\sect}[1]{Section~\ref{#1}}
\renewcommand{\ttref}[1]{Tony~Table~\ref{#1}}
\renewcommand{\tabref}[1]{Table~\ref{#1}}

\begin{document}
\selectlanguage{american}
\begin{wgTitlepage}
  The broadcast constructor in the Parallelism 2 TS allowed construction from (\code{unsigned})
  \code{int}, allowing e.g. \code{vec<float>() + 1}, which is ill-formed in the CD.
  This breaks existing code that gets ported from the TS to \code{std::simd}.
  The design intent behind \code{std::simd} was for this to work.
  However, the understanding in LEWG appeared to be that we can't get this right without constexpr
  function arguments getting added to the language.
  This paper shows that a \code{consteval} constructor overload together with \code{constexpr}
  exceptions can resolve the issue for \CC{}26 and is a better solution than constexpr function
  arguments would be.
\end{wgTitlepage}

\pagestyle{scrheadings}

\input{changelog}
\input{strawpolls}

\pagebreak
\section{Motivation}

It is very common in floating-point code to simply write e.g. \code{* 2} rather than \code{* 2.f}
when multiplying a \code{float} with a constant:
\medskip\begin{lstlisting}[style=Vc]
float f(float x) { return x * 2; } // converts 2 to float (at compile time)

float g(float x) { return x * 2.; } // converts x to double (at run time)

float h(float x) { return x * 2.f; } // no conversions
\end{lstlisting}

More importantly, using \code{* 2} works reliably in generic code, where the type of \code{x} could
be any arithmetic type.

Since this is so common, \code{std::experimental::simd<T>} made an exception for \code{int} in the
broadcast constructor to not require value-preserving conversions.
Consequently, the TS behavior is:
\medskip\begin{lstlisting}[style=Vc]
using floatv = std::experimental::native_simd<float>;

floatv f(floatv x) { return x * 2; } // converts 2 to float and broadcasts (at
                                     //                               compile time)
floatv g(floatv x) { return x * 2.; } // ill-formed

floatv h(floatv x) { return x * 2.f; } // broadcasts 2.f to floatv
\end{lstlisting}

When porting existing code written against the TS to \CC{}26, the first step is to adjust the types:
\medskip\begin{lstlisting}
using floatv = std::@\wgChange{experimental::native_simd}{simd::vec}@<float>;
\end{lstlisting}
Except for uses of \code{std::experimental::where}, which need to be refactored to use
\code{simd::\MayBreak{}select}, the remaining code should work.
The one place where it doesn't work is code such as in function \code{f}, where \code{2} needs to be
replaced:
\medskip\begin{lstlisting}[style=Vc]
floatv f(floatv x) { return x * @\wgChange{2}{std::cw<2>}@; }
\end{lstlisting}

Since we don't have \code{constexpr} function arguments in the language, \code{std::simd} works
around it by recognizing \exposid{integral-constant-like} / \code{constant-wrapper-like} types, that
encode a \emph{value} into a type.
This, however, comes at a compile-time cost.
Every different value leads to a template specialization of both \code{constant_wrapper} and a
\code{basic_vec} broadcast constructor (with it's helper types/concepts to determine whether the
specialization is allowed).
Consequently, for \code{vec<float>}, I would recommend to always use an \code{f} suffix rather than
\code{std::cw}.

But that solution is fairly limited, since we don't have literals for 8-bit and 16-bit integers in
the language.
A function template like
\medskip\begin{lstlisting}[style=Vc]
template <simd_integral V>
V f(V x) {
  return x + 1; // ill-formed for V::value_type = (u)int8_t, (un)int16_t, and uint32_t
}
\end{lstlisting}
needs to use \code{x + V(1)}\footnote{explicit conversion to \code{basic_vec} allows conversions
that are not value-preserving}.
A clever user might write \lstinline@x + '\1'@ instead.
But that fails for the \code{char} type with different signedness.

Consequently, users would need to get used to writing explicit conversions for the constants they
use in \code{std::simd} code.
That's not only verbose and ugly, it is also error-prone.
Whenever we coerce our users into writing explicit conversions, then value-changing conversions
cannot be diagnosed as erroneous anymore.
An explicit \code{static_cast<uint64_t>(-1)} means \code{0xffff'ffff'ffff'ffff}, whereas
\code{uint64_t x = -1} could have been intended to mean \code{0x0000'0000'ffff'ffff} or is a result
of a logic flaw in the code.
E.g., GCC's \code{-Wsign-conversion} diagnoses the latter, but not the former\footnote{And that's
useful, because the former says “I'm intentionally doing this conversion, no need to warn.”}.

If, with \CC{}26, our users are starting to explicitly convert their \code{int} constants to
\code{basic_vec}, then the interface of \code{basic_vec} is at least in part guilty for introducing
harder to find bugs.

\ttref{tt:add-an-offset} presents an example of the solution\footnote{I got bitten by this in my
\code{std::simd} unit tests}.
Note that the code on the left will never warn about the value-changing conversion, even with all
conversion related warnings enabled.
This is due to the explicit conversion, which is telling the compiler “I know what I'm doing; no
need to warn me about it”.
\begin{tonytable}{Add an offset}\label{tt:add-an-offset}
  \begin{lstlisting}
template <simd_floating_point V>
V f(V x) {
  return x + V(0x5EAF00D);
}

f(vec<double>()); // OK

// compiles but adds 99282960 instead of 99282957
f(vec<float>());

// compiles but adds infinity instead of 99282957
f(vec<std::float16_t>());
  \end{lstlisting}
  &
  \begin{lstlisting}
template <simd_floating_point V>
V f(V x) {
  return x + 0x5EAF00D;
}

f(vec<double>()); // OK

// ill-formed: value-changing conversion
f(vec<float>());

// ill-formed: value-changing conversion
f(vec<std::float16_t>());
  \end{lstlisting}
\end{tonytable}%

A safer implementation of the code on the left side of \ttref{tt:add-an-offset} (without this paper)
would have been to write \code{x + std::cw<0x5EAF00D>} instead.
Then the value-changing conversion would have resulted in a constraint failure on the broadcast
constructor.
However, \code{V(0x5EAF00D)} is shorter and needs fewer template instantations.
I expect most users (including myself) will/do not use \code{std::cw} all over the place.

\section{Design space}
In the design review of P1928 of this issue of the broadcast constructor it was overlooked (and
never discussed) that a \code{consteval} overload of the broadcast constructor could solve this
problem.
Before \code{constexpr} exceptions, we would have worded it to be ill-formed (by unspecified means)
if the value changes on conversion to the \code{basic_vec}'s value-type.
Now that we have \code{constexpr} exceptions, we can specify a \code{consteval} broadcast overload
that throws on value-changing conversion.
If the caller cares, the exception can even be handled at compile time.
(I believe it should not throw in \CC{}26, for a minimal change to the WD this late in the \CC{}26
cycle.)

Ordering the overloads for overload resolution is tricky, which is another reason why we should
consider this issue before \CC{}26 ships and potentially take action even if we don't add a
\code{consteval} overload.
Overload resolution does not take \code{consteval} into account.
The process of finding candidate functions%
\href{https://eel.is/c++draft/over.match#funcs.general-8}{\iref{over.match.funcs.general}}, however,
does remove explicit constructors from the candidate set if the
context does not allow the explicit constructor to be called.

\subsection{potentially-convertible-to}
R0 proposed to allow any conversion from arithmetic type \code{U}, that satisfies
\code{convertible_to<value_type>} and does not satisfy
\code{\exposid{value-preserving-convertible-to}<value_type>} via the \code{consteval} broadcast
constructor.
This was too broad, since it would lead to \code{vec<\MayBreak{}float>() + 1.5} being valid
(of type \code{vec<float>}).
While technically not wrong (no loss on conversion from \code{1.5}), it is too surprising that an
operation involving a \code{double} operand is evaluated in single precision.

Therefore, R1 of this paper tightens the constraints for the \code{consteval} broadcast to producing
a less surprising common type.
If the given constant is of arithmetic type \code{T}, then we now require \code{common_type_t<T,
value_type>} to be \code{value_type}.
Since \code{common_type_t<\MayBreak{}double, float>} is \code{double}, the expression
\code{vec<float>() + 1.5} becomes ill-formed.
However, this rule alone still breaks the case of \code{vec<short>() + 1}, which the user cannot
changed to use a \code{short} literal (because we don't have one).
The TS made an explicit exception for \code{int} and \code{unsigned int}\footnote{%
  The TS broadcast constructor has a constraint “[\ldots], or \code{From} is \code{int}, or
  \code{From} is \code{unsigned int} and \code{value_type} is an unsigned integral type.”
}, which is what we still
need for integer types (with lower rank than \code{int}).

So the final \exposid{potentially-convertible-to} constraint looks like this:
\medskip\begin{lstlisting}[style=Vc]
template <typename From, typename To>
  concept @\exposid{potentially-convertible-to}@ = is_arithmetic_v<From>
    && convertible_to<From, To> && !@\exposid{value-preserving-convertible-to}@<From, To>
    && (is_same_v<common_type_t<From, To>, To>
      || (is_same_v<From, int> && is_integral_v<To>)
      || (is_same_v<From, unsigned> && unsigned_integral<To>));
\end{lstlisting}

\subsection{Status quo}
The following code shows the properties of the current broadcast constructor.
See Appendix \ref{sec:really-convertible} for the definition of the \code{really_convertible_to}
concept.

\bigskip
\begin{lstlisting}[style=Vc]
using V = simd::vec<float>;

template <typename T> struct X { explicit operator T() const; };

template <typename... Ts>
concept has_common_type = requires { typename std::common_type_t<Ts...>; };

static_assert(not   std::convertible_to<X<float>, V>);
static_assert(      std::convertible_to<float, V>);
static_assert(      std::convertible_to<short, V>);
static_assert(    really_convertible_to<short, V>);
static_assert(not   std::convertible_to<int, V>);
static_assert(not really_convertible_to<int, V>);

static_assert(    std::constructible_from<V, X<float>>);
static_assert(not std::constructible_from<V, X<short>>);
static_assert(    std::constructible_from<V, double>);
static_assert(    std::constructible_from<V, float>);
static_assert(    std::constructible_from<V, short>);
static_assert(    std::constructible_from<V, int>);

static_assert(not has_common_type<V, double>);
static_assert(not has_common_type<V, int>);

V f(int n, short m, std::reference_wrapper<int> l, std::reference_wrapper<float> f)
{
  V x = '\1'; // OK
  x = 1;      // ill-formed
  x = 0x5EAF00D; // ill-formed
  x = V(n);   // OK
  x = m;      // OK
  x = l;      // OK (because convertible_to<decltype(l), float> is true)
  x = f;      // OK
  x = 1.1;    // ill-formed
  x = V(1.1); // OK
  x = X<float>(); // ill-formed: no match for operator= (no known conversion […])
  x = float(X<float>()); // OK (obvious)
  x = V(X<float>()); // OK
}
\end{lstlisting}

\subsection{More constrained \code{constexpr} overload}\label{sec:explicit}
A possible solution selects the existing (\code{constexpr}) broadcast constructor for
everything but the cases where the value of the argument needs to be checked.
Thus, we need the existing constructor to always be \emph{more constrained} \iref{temp.constr.order}
than the \code{consteval} constructor.
The \code{consteval} constructor can then only be selected if the other constructor is not part of
the candidate set at all (via \code{explicit}).

Sketch:
\medskip\begin{lstlisting}[style=Vc]
template <class From, class To>
  concept @\exposconcept{simd-consteval-broadcast-arg}@ = @\exposconcept{explicitly-convertible-to}@<From, To>;

template <class From, class To>
  concept @\exposconcept{simd-broadcast-arg}@ = @\exposconcept{simd-consteval-broadcast-arg}@<From, To> and true;

template <class T>
class basic_vec
{
public:
  template <@\exposconcept{simd-broadcast-arg}@<T> U>
    constexpr explicit(@\seebelow@) basic_vec(U&&); // #1
  template <@\exposconcept{simd-consteval-broadcast-arg}@<T> U>
    consteval basic_vec(U&&);                    // #2
    // Mandates: @\exposconcept{potentially-convertible-to}@<remove_cvref_t<U>, value_type>
};
\end{lstlisting}

Now every explicit call to the broadcast constructor will always select \code{\#1}.
Implicit calls to the broadcast constructor will select \code{\#1} if the condition in the
\code{explicit} specifier is \code{false}.
Otherwise, \code{\#1} is not part of the candidate set and \code{\#2} is called.
Thus, the condition on the \code{explicit} specifier determines whether the \code{consteval}
overload is chosen or not.

\bigskip
\begin{lstlisting}[style=Vc]
static_assert(      std::convertible_to<X<float>, V>); // different to status quo
static_assert(      std::convertible_to<float, V>);
static_assert(      std::convertible_to<short, V>);
static_assert(    really_convertible_to<short, V>);
static_assert(      std::convertible_to<int, V>);      // different to status quo
static_assert(not really_convertible_to<int, V>);

static_assert(    std::constructible_from<V, X<float>>);
static_assert(not std::constructible_from<V, X<short>>);
static_assert(    std::constructible_from<V, double>);
static_assert(    std::constructible_from<V, float>);
static_assert(    std::constructible_from<V, short>);
static_assert(    std::constructible_from<V, int>);

static_assert(not has_common_type<V, double>);
static_assert(    has_common_type<V, int>); // it's vec<float>

V f(int n, short m, std::reference_wrapper<int> l, std::reference_wrapper<float> f)
{
  V x = '\1'; // OK
  x = 1;      // OK (different to status quo)
  x = 0x5EAF00D; // ill-formed
  x = V(n);   // OK
  x = m;      // OK
  x = V(l);   // OK
  x = f;      // OK
  x = 1.1;    // ill-formed
  x = V(1.1); // OK
  x = X<float>(); // ill-formed: static_assert failed (different reason to status quo)
  x = float(X<float>()); // OK (obvious)
  x = V(X<float>()); // OK
}
\end{lstlisting}

\subsection{More constrained \code{consteval} overload}\label{sec:consteval}
A viable alternative involves the removal of explicit conversions from arithmetic types to
\code{basic_vec}.
The \code{consteval} constructor is declared with additional constraints over the existing
constructor (satisfies \code{convertible_to}, \code{is_arithmetic_v}, and not value-preserving
conversion).
This way the \code{consteval} constructor is always chosen if the conversion of the given
(arithmetic) type to \code{value_type} is \exposid{potentially-convertible-to}.
Otherwise, the \code{constexpr} overload is used.

Sketch:
\medskip\begin{lstlisting}[style=Vc]
template <class From, class To>
  concept @\exposconcept{simd-broadcast-arg}@ = @\exposconcept{explicitly-convertible-to}@<From, To>;

template <class From, class To>
  concept @\exposconcept{simd-consteval-broadcast-arg}@ =
    @\exposconcept{simd-broadcast-arg}@<From, To> && @\exposconcept{potentially-convertible-to}@<remove_cvref_t<From>, To>;

template <class T>
class basic_vec
{
public:
  template <@\exposconcept{simd-broadcast-arg}@<T> U>
    constexpr explicit(@\seebelow@) basic_vec(U&&); // #1
  template <@\exposconcept{simd-consteval-broadcast-arg}@<T> U>
    consteval basic_vec(U&&); // #2
};
\end{lstlisting}

Here, every explicit call to the broadcast constructor with a type \code{U} that satisfies
\code{\exposid{poten\-tial\-ly-convertible-to}<T>} is equivalent to an implicit conversion, since the
\code{consteval} overload is viable and more constrained.
Every type with a value-preserving conversion to \code{T} will select \code{\#1} (because of the
constraint on \code{\#2}).
Every non-arithmetic type (notably, user-defined types with conversion operator to some arithmetic
type) will continue to work as today, since \code{\#2} is not viable.

\bigskip
\begin{lstlisting}[style=Vc]
static_assert(not   std::convertible_to<X<float>, V>); // equal to status quo / different to above
static_assert(      std::convertible_to<float, V>);
static_assert(      std::convertible_to<short, V>);
static_assert(    really_convertible_to<short, V>);
static_assert(      std::convertible_to<int, V>);      // different to status quo / equal to above
static_assert(not really_convertible_to<int, V>);

static_assert(    std::constructible_from<V, X<float>>);
static_assert(not std::constructible_from<V, X<short>>);
static_assert(    std::constructible_from<V, double>);
static_assert(    std::constructible_from<V, float>);
static_assert(    std::constructible_from<V, short>);
static_assert(    std::constructible_from<V, int>);

static_assert(not has_common_type<V, double>);
static_assert(    has_common_type<V, int>); // it's vec<float>

V f(int n, short m, std::reference_wrapper<int> l, std::reference_wrapper<float> f)
{
  V x = '\1'; // OK
  x = 1;      // OK (different to status quo / equal to above)
  x = 0x5EAF00D; // ill-formed
  x = V(n);   // ill-formed (different to both)
  x = m;      // OK
  x = V(l);   // OK
  x = f;      // OK
  x = 1.1;    // ill-formed
  x = V(1.1); // OK
  x = X<float>(); // ill-formed: no match for operator= (no known conversion […])
  x = float(X<float>()); // OK (obvious)
  x = V(X<float>()); // OK
}
\end{lstlisting}

\subsection{How to handle bad value-preserving casts}\label{sec:exceptions}

The \code{consteval} broadcast overload needs to be ill-formed if the argument value cannot be
converted to the value type without changing the value.
This can be achieved via the mechanism used in \iref{simd.bit} for \code{bit_ceil}.
The constructor would spell out a precondition followed by \remarks An expression that violates
the precondition in the \expects element is not a core constant expression\iref{expr.const}.

The alternative that was mentioned before is to throw an exception (at compile time).
Since in basically all cases such an exception would not be caught at compile time, the program
becomes ill-formed.
The ability to catch the exception allowed me to hack up a \code{really_convertible_to} concept.
But otherwise, the utility of using an exception here seems fairly limited.
The main reason for using an exception is better diagnostics on ill-formed programs.
If we decide to add the \code{consteval} constructor for \CC{}26, then we might want to delay the
new exception type for \CC{}29, though.

\section{Differences}

\newcommand\good{\color[rgb]{0,.4,.2}\ding{52} }
\newcommand\bad{\color[rgb]{.5,0,0}\ding{56} }

Differences between the status quo and the two alternatives above:\\
\begin{tabular}{l|rrr}
  & status quo & \sect{sec:explicit} & \sect{sec:consteval} \\ \hline
  \code{convertible_to<X<float>, V>}     & \false & \true & \false \\
  \code{convertible_to<int, V>}          & \false & \true & \true \\
  \code{common_type_t<V, int>}           & \bad   & \code{V} & \code{V} \\
  \code{x = 1;}                          & \bad   & \good & \good \\
  \code{x = V(n);}                       & \good  & \good & \bad \\
\end{tabular}

\medskip
Note that \code{X<float>} is never implicitly convertible to \code{vec<float>}, so the solution in
\sect{sec:explicit} lies about that.
Also while some values of constant expressions of type \code{int} are convertible to
\code{vec<float>}, it is not true in general that \code{int} is convertible to \code{vec<float>}.

\section{Should \code{common_type} really change? What if it does?}

After \code{convertible_to} changes, consequently also conditional expressions such as
\code{false ? vec<\MayBreak{}float>() : 1} become valid.
\code{common_type_t<\MayBreak{}vec<\MayBreak{}float>, int>} simply reflects that.
The surprising aspect, similar to \code{convertible_to}, is that this isn't true in general.

If we accept that \code{common_type} changes (we don't have to, as we can specialize
\code{common_type}), this has consquences on [simd.math].
Multi-argument math functions use \code{common_type} in it's specification to spell out the design
intent to match \code{<cmath>} overloads of these functions.
For some background, let's use 2-arg \code{std::hypot} as an example.
C defines three functions \code{hypot}, \code{hypotf}, and \code{hypotl}.
\CC{} then overloads \code{hypot(double, double)} with \code{hypot(\MayBreak{}float, float)}, and
\code{hypot(long double, long double)} (and since \CC{}23 also \code{std::\MayBreak{}floatN_t}).
It is not correct to implement this as \code{template <class T> hypot(T, T)}, since a call to
\code{hypot(1., 1)} would then be ill-formed.
With explicit overloads \code{hypot(1., 1)} calls \code{hypot(\MayBreak{}double, double)}.

The std::simd (and TS) math overloads were designed to match that behavior.
The mechanism for this was spelled out after the design went into LWG wording review for \CC{}26.
For std::simd it's not as simple as spelling out all overloads.
Consider an implementation that supports up to 256 elements in a \code{basic_vec}.
The float overloads would need a minimum of 256 overloads (\code{hypot(vec<float, N>, vec<float,
N>)}).
But actually more are needed because of differences in ABI tags (vector mask vs. bit mask;
different register widths for different targets).
That explosion in function overloads just isn't reasonable to spell out (neither in the standard,
nor in an implementation).

Therefore, std::simd uses function templates.
The 2-arg \code{hypot} function is declared as:
\medskip\begin{lstlisting}[style=Vc]
template <class V0, class V1>
  @\exposid{math-common-simd-t}@<V0, V1> hypot(const V0& x, const V1& y);
\end{lstlisting}
The return type is constrained such that at least one of \code{V0} and \code{V1} is a
\code{basic_vec} of floating-point type\footnote{or is like a \code{reference_wrapper}}.
In the common cases the \exposid{math-common-simd-t} alias is simply \code{common_type_t<V0, V1>}.
If \code{common_type} has no type member, then the overload is removed from the overload set
(SFINAE).
The status-quo is that for \code{simd::hypot(vec<float>(), 1)}
\code{\exposid{math-common-simd-t}<vec<float>, int>} is not valid and thus no viable
\code{simd::hypot} overload exists.

The above proposal makes \code{\exposid{math-common-simd-t}<vec<float>, int>} a valid type.
In principle, that's correct, because \code{1} can be represented without loss of value as a
\code{float}.

The question is what should happen for \code{simd::hypot(vec<float>(), 0x5EAF00D)}, which would need
to convert \code{0x5EAF00D} to \code{float} inside the \code{hypot} implementation and thereby
change its value.
Currently, the \exposid{make-compatible-simd-t} trait converts \code{0x5EAF00D} from \code{int} to
\code{vec<int, vec<\MayBreak{}float>\MayBreak{}::size()>}.
If the \exposid{make-compatible-simd-t<V, T>} trait is changed to instead be an alias for
\code{V}\footnote{Also the classification and comparison functions need to be split off in the
wording to provide the correct template argument to \exposid{make-compatible-simd-t}.} rather than
\code{vec<T, V::size()>}, then the as-if implementation requires a conversion to \code{vec<float>},
and thus implying the broadcast constructor behavior.

\section{broadcast as immediate-escalating expression}\label{sec:math}
Refresher (\url{https://compiler-explorer.com/z/qvdoxavMK}):
\medskip\begin{lstlisting}[style=Vc]
struct A
{ consteval A(int) {} };

constexpr A f(int, auto y) // f gets promoted to an immediate function
{ return y; } // immediate-escalating expression 'A(y)'

A test(int x)
{ return f(x, 1); } // Error: 'x' is not a constant expression
\end{lstlisting}

If we remove \code{constexpr} from \code{f}, the underlying
issue becomes apparent:
\code{f} calls a \code{consteval} constructor that uses \code{y} as it's argument.
And that can't work, because \code{y} is not a constant expression.
The magic of promotion to immediate function simply makes the compiler try harder to make it compile
anyway.

\subsection{escalating [simd.math] functions}

Any \code{simd::vec} broadcast expression that promotes the surrounding function to an immediate
function becomes “interesting” if not surprising or problematic.
The [simd.math] functions as discussed above are affected.
While \code{simd::hypot(vec<float>(), 1)} is fine (because the first argument is a constant
expression),
\medskip\begin{lstlisting}[style=Vc]
auto f(simd::vec<float> x) { return simd::hypot(x, 1); }
\end{lstlisting}
is not, even though \code{1} can convert to \code{float} without loss of value.
That's because the \code{hypot} implementation needs to call a \code{consteval} function, which then
promotes \code{hypot} itself to an immediate function, which in turn requires all arguments to
\code{hypot} to be constant expressions.
If immediate-escalation were not applied, then the conversion from \code{int} to
\code{vec<float>} inside of \code{hypot} would be ill-formed.
Either way, \code{simd::hypot(x, 1)} with not-constant \code{x} cannot be valid.

\subsection{move conversions before math calls}\label{sec:math2}

We can respecify [simd.math] in such a way that conversions happen before the function is called,
mirroring the actual behavior of \code{<cmath>} overloads.
For 2-arg math functions we would have to change from one function template to three function
templates:
\medskip\begin{lstlisting}[style=Vc]
template<class V>
  constexpr @\exposid{deduced-vec-t}@<V>
  hypot(const V&, const V&);

template<class V>
  constexpr @\exposid{deduced-vec-t}@<V>
  hypot(const V&, const @\exposid{deduced-vec-t}@<V>&);

template<class V>
  constexpr @\exposid{deduced-vec-t}@<V>
  hypot(const @\exposid{deduced-vec-t}@<V>&, const V&);
\end{lstlisting}
However, for 3-arg math functions we would have to change to seven function templates.
I can report that this works for all my test cases.
I believe I tested a representative set of argument types and permutations.%
\footnote{I tested arguments of type \code{reference_wrapper<vec<float>>},
  \code{reference_wrapper<float>}, \code{reference_wrapper<short>}, \code{vec<float>}, \code{float},
  \code{short}, and immediate arguments with value \code{1} (consteval broadcast from \code{int}). I
  tested all permutations where at least one argument is either \code{vec<float>} or
  \code{reference_wrapper<vec<float>>}.
}
\medskip\begin{lstlisting}[style=Vc]
template<class V>
  constexpr @\exposid{deduced-vec-t}@<V>
  hypot(const V&, const V&, const V&);

template<class V>
  constexpr @\exposid{deduced-vec-t}@<V>
  hypot(const V&, const @\exposid{deduced-vec-t}@<V>&, const @\exposid{deduced-vec-t}@<V>&);

template<class V>
  constexpr @\exposid{deduced-vec-t}@<V>
  hypot(const @\exposid{deduced-vec-t}@<V>&, const V&, const @\exposid{deduced-vec-t}@<V>&);

template<class V>
  constexpr @\exposid{deduced-vec-t}@<V>
  hypot(const @\exposid{deduced-vec-t}@<V>&, const @\exposid{deduced-vec-t}@<V>&, const V&);

template<class V>
  constexpr @\exposid{deduced-vec-t}@<V>
  hypot(const V&, const V&, const @\exposid{deduced-vec-t}@<V>&);

template<class V>
  constexpr @\exposid{deduced-vec-t}@<V>
  hypot(const V&, const @\exposid{deduced-vec-t}@<V>&, const V&);

template<class V>
  constexpr @\exposid{deduced-vec-t}@<V>
  hypot(const @\exposid{deduced-vec-t}@<V>&, const V&, const V&);
\end{lstlisting}

\subsection{Alternative via “expression alias” P2826}

P2826, which is awaiting a revision for consideration for \CC{}29, could solve this more elegantly.
However, we don't have the feature available yet.
Thus we would need to ship \CC{}26 with a [simd.math] specification that is forward-compatible 

\subsection{The importantance of conversions}

Consider the \code{pow} function.
It is fairly common to call \code{pow} with an integral exponent, e.g.
\medskip\begin{lstlisting}[style=Vc]
std::pow(x, 3); // x³
\end{lstlisting}
This is well-formed if \code{x} is of floating-point type.
It would be unfortunate if the same expression would not work for \code{x} of type
\code{vec<\exposid{floating-point-type}>}.


\section{Implementation experience}
Both solutions (and a lot more variants that were discarded) have been implemented and tested in my
implementation.
Several days (if not weeks) of exploration and testing went into this paper.
I implemented the \code{consteval} overloads for a complete set of vectorizable types with an
ability to select between the different behaviors discussed in this paper.\footnote{The code is
currently in patch review for libstdc++.}
A representative set of [simd.math] is implemented.


\section{Recommendation}

My recommendation is:
\begin{itemize}
  \item Adopt with the solution presented in \sect{sec:consteval},
  \item without a new exception type (\sect{sec:exceptions}), and
  \item change [simd.math] to the overload sets presented in \sect{sec:math2} for \CC{}26.
\end{itemize}
This would roll back a small part of a recent change done by \cite{P3430R3}.

Hope for P2826 “Replacement function” --- the paper is getting renamed to “expression alias” --- to
get into \CC{}29 and provide a simple way to restore \code{<cmath>}-like overload resolution and
conversions on [simd.math] functions.

Rationale for my preference:
\begin{enumerate}
  \item The explicit conversion from arithmetic types via broadcast constructor is significantly
    less important after implicit conversion from constant expressions becomes possible.
  \item The new \code{consteval} overload cannot be fully constrained in the solution presented in
    \sect{sec:explicit}, leading to incorrect answers on traits or in requires expressions.
  \item This should be part of \CC{}26 because it helps avoiding bugs in user code.
  \item A new exception type is not important enough to add it to \CC{}26 and it can easily be added
    later.
  \item{} [simd.math] was already complicated; making it more complicated is not warranted.
    Either we get a language feature to make it work or users have to be explicit about conversions.
\end{enumerate}

If LEWG is uncomfortable with adding the \code{consteval} overload now I recommend to:
\begin{itemize}
  \item remove explicit broadcasts and
  \item simplify [simd.math] to \code{template<class T> T fun(T, T)} for \CC{}26.
\end{itemize}

\section{Proposed polls}

\wgPoll{Something needs to be done for \CC{}26. (If we do nothing, the design space is constrained
and \sect{sec:consteval} would be a breaking change.)}{&&&&}

\wgPoll{Add a \code{consteval} broadcast overload for value-preserving conversions to
\CC{}26.}{&&&&}

\noindent If the vote for \CC{}26 failed:\\
\wgPoll{Add a \code{consteval} broadcast overload for value-preserving conversions to
\CC{}29.}{&&&&}

\noindent Otherwise \emph{maybe} poll:\\
\wgPoll{It is better to add a \code{consteval} broadcast overload for \CC{}29 rather than
\CC{}26.}{&&&&}

\noindent Note: The next poll makes sense for \CC{}26, even if we only intend to add the new
overload for \CC{}29.\\
\wgPoll{The new constructor overload should be fully constrained, which requires the removal of
\code{explicit} (not value-preserving conversions) from the existing broadcast constructor.}{&&&&}

\wgPoll{Add a new exception type to \CC{}26 that is thrown for value-changing conversions from the
new \code{consteval} broadcast constructor.}{&&&&}

\wgPoll{Encourage a paper targeting \CC{}29 on a new exception type that is thrown from the new
\code{consteval} broadcast constructor.}{&&&&}

\wgPoll{Modify [simd.math] functions to allow conversion in the caller on function arguments (as
presented in \sect{sec:math2}) for \CC{}26.}{&&&&}

\wgPoll{Simplify [simd.math] functions to use \code{template<\exposid{simd-floating-point} T> T
fun(T, T)} signatures (for now/\CC{}26), hoping we can restore \code{<cmath>}-like behavior for
\CC{}29.}{&&&&}

%\input{wording1}

\input{wording2}

\section{Wording changes for [simd.math]}

A set of fairly mechanical changes.
TBD.

\appendix
\let\appendix=\relax
\section{\code{really_convertible_to} definition}\label{sec:really-convertible}
\medskip\begin{lstlisting}[style=Vc]
template <typename To, typename From>
  consteval bool converting_limits_throws()
  {
    try {
      using L = std::numeric_limits<From>;
      [[maybe_unused]] To x = L::max();
      x = L::min();
      x = L::lowest();
    } catch(...) {
      return true;
    }
    return false;
  }

template <typename From, typename To>
  concept really_convertible_to = std::convertible_to<From, To>
                                    and not converting_limits_throws<To, From>();
\end{lstlisting}


\end{document}
% vim: sw=2 sts=2 ai et tw=100
